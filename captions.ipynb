{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a581e711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/afs/cs.wisc.edu/u/z/i/ziyangc/Github/CLIP_OOD\n"
     ]
    }
   ],
   "source": [
    "! pwd\n",
    "DATASET = 'CIFAR-100'\n",
    "cifar_train = True\n",
    "data_path = None\n",
    "if DATASET == 'ImageNet':\n",
    "    data_path = '/nobackup-slow/dataset/ILSVRC-2012/train'\n",
    "elif DATASET == 'CIFAR-10' or DATASET == 'CIFAR-100':\n",
    "    data_path = '/nobackup-slow/dataset/cifarpy'\n",
    "else:\n",
    "    data_path = '/nobackup-slow/dataset/ImageNet_OOD_dataset/{}'.format(DATASET)\n",
    "sg_benchmark_path = '/nobackup-fast/ziyangc/scene_graph_benchmark'\n",
    "oscar_path = '/nobackup-fast/ziyangc/Oscar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b121923b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: delete this cell\n",
    "import sys\n",
    "sys.path.append('/nobackup-fast/ziyangc/scene_graph_benchmark')\n",
    "import maskrcnn_benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "193a1f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 2813/10000 [01:46<03:01, 39.66it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "100%|██████████| 10000/10000 [06:20<00:00, 26.28it/s]\n",
      "9997it [00:00, 257892.34it/s]\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import cv2\n",
    "import json\n",
    "import os.path as op\n",
    "import os\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "from maskrcnn_benchmark.structures.tsv_file_ops import tsv_reader, tsv_writer\n",
    "from maskrcnn_benchmark.structures.tsv_file_ops import generate_linelist_file\n",
    "from maskrcnn_benchmark.structures.tsv_file_ops import generate_hw_file\n",
    "from maskrcnn_benchmark.structures.tsv_file import TSVFile\n",
    "from maskrcnn_benchmark.data.datasets.utils.image_ops import img_from_base64\n",
    "\n",
    "# To generate a tsv file:\n",
    "get_class_name = {\n",
    "    'ImageNet': lambda p, f: p.split('/')[-1],\n",
    "    'iNaturalist': lambda p, f: 'OOD',\n",
    "    'Places': lambda p, f: f.split('_')[1],\n",
    "    'Textures': lambda p, f: p.split('/')[-1],\n",
    "    'SUN': lambda p, f: 'OOD'\n",
    "}\n",
    "\n",
    "filter_classes = {\n",
    "    'ImageNet': True,\n",
    "    'iNaturalist': False,\n",
    "    'Places': False,\n",
    "    'Textures': False,\n",
    "    'SUN': False\n",
    "}\n",
    "\n",
    "test_classes = {'n04552348', 'n04285008', 'n01530575', 'n02123597', 'n02422699', 'n02107574', 'n01641577', 'n01728572', 'n03095699', 'n03417042'}\n",
    "tsv_data_path = os.path.join(sg_benchmark_path, 'tools/mini_tsv/data/')\n",
    "ImageNet_classes = {key: string for [key, string] in json.load(open(\"/nobackup-fast/ziyangc/imagenet_class_index.json\")).values()}\n",
    "img_list = [(path, f) for (path, _, files) in os.walk(data_path) for f in files if (f.lower().endswith(\".jpeg\") or f.lower().endswith('jpg')) and (not filter_classes[DATASET] or path.split('/')[-1] in test_classes)]\n",
    "tsv_file = \"{}.test.tsv\".format(DATASET)\n",
    "label_file = \"{}.test.label.tsv\".format(DATASET)\n",
    "hw_file = \"{}.test.hw.tsv\".format(DATASET)\n",
    "linelist_file = \"{}.test.linelist.tsv\".format(DATASET)\n",
    "\n",
    "rows = []\n",
    "rows_label = []\n",
    "rows_hw = []\n",
    "for (path, filename) in tqdm(img_list):\n",
    "    class_name =  get_class_name[DATASET](path, filename)\n",
    "    img_key = class_name + '_' + filename.split('.')[0]\n",
    "    img_path = op.join(path, filename)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None: continue\n",
    "    img_encoded_str = base64.b64encode(cv2.imencode('.jpg', img)[1])\n",
    "\n",
    "    # Here is just a toy example of labels.\n",
    "    # The real labels can be generated from the annotation files\n",
    "    # given by each dataset. The label is a list of dictionary\n",
    "    # where each box with at least \"rect\" (xyxy mode) and \"class\"\n",
    "    # fields. It can have any other fields given by the dataset.\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "\n",
    "    labels = []\n",
    "    # labels.append({\"rect\": [1, 1, height, width], \"class\": ImageNet_classes[class_name]})\n",
    "    labels.append({\"rect\": [1, 1, height, width], \"class\": class_name})\n",
    "\n",
    "    row = [img_key, img_encoded_str]\n",
    "    rows.append(row)\n",
    "\n",
    "    row_label = [img_key, json.dumps(labels)]\n",
    "    rows_label.append(row_label)\n",
    "\n",
    "    row_hw = [img_key, json.dumps([{\"height\": height, \"width\": width}])]\n",
    "    rows_hw.append(row_hw)\n",
    "\n",
    "tsv_writer(rows, os.path.join(tsv_data_path, tsv_file))\n",
    "tsv_writer(rows_label, os.path.join(tsv_data_path, label_file))\n",
    "tsv_writer(rows_hw, os.path.join(tsv_data_path, hw_file))\n",
    "\n",
    "# generate linelist file\n",
    "generate_linelist_file(os.path.join(tsv_data_path, label_file), save_file=os.path.join(tsv_data_path, linelist_file))\n",
    "\n",
    "yaml_dict = {\"img\": tsv_file,\n",
    "            \"label\": label_file,\n",
    "            \"hw\": hw_file,\n",
    "            \"linelist\": linelist_file}\n",
    "\n",
    "with open(op.join(tsv_data_path, '{}.test.yaml'.format(DATASET)), 'w') as file:\n",
    "        yaml.dump(yaml_dict, file)\n",
    "\n",
    "# To access a tsv file:\n",
    "# 1) Use tsv_reader to read dataset in given order\n",
    "# rows = tsv_reader(\"tools/mini_tsv/data/train.tsv\")\n",
    "# rows_label = tsv_reader(\"tools/mini_tsv/data/train.label.tsv\")\n",
    "# for row, row_label in zip(rows, rows_label):\n",
    "#     img_key = row[0]\n",
    "#     labels = json.loads(row_label[1])\n",
    "#     img = img_from_base64(row[1])\n",
    "\n",
    "# 2) use TSVFile to access dataset at any given row.\n",
    "# tsv = TSVFile(\"tools/mini_tsv/data/train.tsv\")\n",
    "# row = tsv.seek(1) # to access the second row\n",
    "# img_key = row[0]\n",
    "# img = img_from_base64(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (3455061386.py, line 27)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_348154/3455061386.py\"\u001b[0;36m, line \u001b[0;32m27\u001b[0m\n\u001b[0;31m    return\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import cv2\n",
    "import json\n",
    "import os.path as op\n",
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from maskrcnn_benchmark.structures.tsv_file_ops import tsv_reader, tsv_writer\n",
    "from maskrcnn_benchmark.structures.tsv_file_ops import generate_linelist_file\n",
    "from maskrcnn_benchmark.structures.tsv_file_ops import generate_hw_file\n",
    "from maskrcnn_benchmark.structures.tsv_file import TSVFile\n",
    "from maskrcnn_benchmark.data.datasets.utils.image_ops import img_from_base64\n",
    "from torchvision import datasets\n",
    "\n",
    "# To generate a tsv file:\n",
    "if not cifar_train: DATASET = DATASET + '-val'\n",
    "tsv_data_path = os.path.join(sg_benchmark_path, 'tools/mini_tsv/data/')\n",
    "if DATASET == 'CIFAR-10':\n",
    "    img_ds = datasets.CIFAR10(data_path, train=cifar_train)\n",
    "elif DATASET == 'CIFAR-100':\n",
    "    img_ds = datasets.CIFAR100(data_path, train=cifar_train)\n",
    "tsv_file = \"{}.test.tsv\".format(DATASET)\n",
    "label_file = \"{}.test.label.tsv\".format(DATASET)\n",
    "hw_file = \"{}.test.hw.tsv\".format(DATASET)\n",
    "linelist_file = \"{}.test.linelist.tsv\".format(DATASET)\n",
    "return \n",
    "rows = []\n",
    "rows_label = []\n",
    "rows_hw = []\n",
    "for i, (img, target) in tqdm(enumerate(img_ds)):\n",
    "    class_name =  img_ds.classes[target]\n",
    "    img_key = class_name + '_' + str(i)\n",
    "    if img is None: continue\n",
    "    img = np.array(img)\n",
    "    img_encoded_str = base64.b64encode(cv2.imencode('.jpg', img)[1])\n",
    "\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "\n",
    "    labels = []\n",
    "    # labels.append({\"rect\": [1, 1, height, width], \"class\": ImageNet_classes[class_name]})\n",
    "    labels.append({\"rect\": [1, 1, height, width], \"class\": class_name})\n",
    "\n",
    "    row = [img_key, img_encoded_str]\n",
    "    rows.append(row)\n",
    "\n",
    "    row_label = [img_key, json.dumps(labels)]\n",
    "    rows_label.append(row_label)\n",
    "\n",
    "    row_hw = [img_key, json.dumps([{\"height\": height, \"width\": width}])]\n",
    "    rows_hw.append(row_hw)\n",
    "\n",
    "tsv_writer(rows, os.path.join(tsv_data_path, tsv_file))\n",
    "tsv_writer(rows_label, os.path.join(tsv_data_path, label_file))\n",
    "tsv_writer(rows_hw, os.path.join(tsv_data_path, hw_file))\n",
    "\n",
    "# generate linelist file\n",
    "generate_linelist_file(os.path.join(tsv_data_path, label_file), save_file=os.path.join(tsv_data_path, linelist_file))\n",
    "\n",
    "yaml_dict = {\"img\": tsv_file,\n",
    "            \"label\": label_file,\n",
    "            \"hw\": hw_file,\n",
    "            \"linelist\": linelist_file}\n",
    "\n",
    "with open(op.join(tsv_data_path, '{}.test.yaml'.format(DATASET)), 'w') as file:\n",
    "        yaml.dump(yaml_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10a5cab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR-100.test.hw.lineidx\t ImageNet.test.linelist.lineidx\n",
      "CIFAR-100.test.hw.tsv\t\t ImageNet.test.linelist.tsv\n",
      "CIFAR-100.test.label.lineidx\t ImageNet.test.tsv\n",
      "CIFAR-100.test.label.tsv\t ImageNet.test.yaml\n",
      "CIFAR-100.test.lineidx\t\t SUN.test.hw.lineidx\n",
      "CIFAR-100.test.linelist.lineidx  SUN.test.hw.tsv\n",
      "CIFAR-100.test.linelist.tsv\t SUN.test.label.lineidx\n",
      "CIFAR-100.test.tsv\t\t SUN.test.label.tsv\n",
      "CIFAR-100.test.yaml\t\t SUN.test.lineidx\n",
      "CIFAR-10.test.hw.lineidx\t SUN.test.linelist.lineidx\n",
      "CIFAR-10.test.hw.tsv\t\t SUN.test.linelist.tsv\n",
      "CIFAR-10.test.label.lineidx\t SUN.test.tsv\n",
      "CIFAR-10.test.label.tsv\t\t SUN.test.yaml\n",
      "CIFAR-10.test.lineidx\t\t train.hw.lineidx\n",
      "CIFAR-10.test.linelist.lineidx\t train.hw.tsv\n",
      "CIFAR-10.test.linelist.tsv\t train.label.lineidx\n",
      "CIFAR-10.test.tsv\t\t train.labelmap.tsv\n",
      "CIFAR-10.test.yaml\t\t train.label.tsv\n",
      "ImageNet.test.hw.lineidx\t train.lineidx\n",
      "ImageNet.test.hw.tsv\t\t train.linelist.tsv\n",
      "ImageNet.test.label.lineidx\t train.tsv\n",
      "ImageNet.test.label.tsv\t\t train.yaml\n",
      "ImageNet.test.lineidx\n"
     ]
    }
   ],
   "source": [
    "! ls {tsv_data_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://penzhanwu2.blob.core.windows.net/sgg/sgg_benchmark/vinvl_model_zoo/vinvl_vg_x152c4.pth -P {sg_benchmark_path}/pretrained_model\n",
    "! wget https://penzhanwu2.blob.core.windows.net/sgg/sgg_benchmark/vinvl_model_zoo/VG-SGG-dicts-vgoi6-clipped.json -P {sg_benchmark_path}/visualgenome/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d14c9b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "2022-04-02 12:03:30,392 maskrcnn_benchmark INFO: Using 2 GPUs\n",
      "2022-04-02 12:03:30,392 maskrcnn_benchmark INFO: DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  NUM_WORKERS: 0\n",
      "  SIZE_DIVISIBILITY: 0\n",
      "DATASETS:\n",
      "  FACTORY_TEST: ('VGTSVDataset',)\n",
      "  FACTORY_TRAIN: ('VGTSVDataset',)\n",
      "  LABELMAP_FILE: visualgenome/VG-SGG-dicts-vgoi6-clipped.json\n",
      "  TEST: ('CIFAR-100.test.yaml',)\n",
      "  TRAIN: ('visualgenome/train_vgoi6_clipped.yaml',)\n",
      "DATA_DIR: tools/mini_tsv/data\n",
      "DISTRIBUTED_BACKEND: gloo\n",
      "DTYPE: float32\n",
      "INPUT:\n",
      "  BRIGHTNESS: 0.0\n",
      "  CONTRAST: 0.0\n",
      "  HORIZONTAL_FLIP_PROB_TRAIN: 0.5\n",
      "  HUE: 0.0\n",
      "  MAX_SIZE_TEST: 1000\n",
      "  MAX_SIZE_TRAIN: 1333\n",
      "  MIN_SIZE_TEST: 600\n",
      "  MIN_SIZE_TRAIN: (800,)\n",
      "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  SATURATION: 0.0\n",
      "  TO_BGR255: True\n",
      "  VERTICAL_FLIP_PROB_TRAIN: 0.0\n",
      "LOG_LOSS_PERIOD: 20\n",
      "MODEL:\n",
      "  ATTRIBUTE_ON: True\n",
      "  BACKBONE:\n",
      "    CONV_BODY: R-152-C4\n",
      "    FREEZE_CONV_BODY_AT: 2\n",
      "  CLS_AGNOSTIC_BBOX_REG: False\n",
      "  DEVICE: cuda\n",
      "  FBNET:\n",
      "    ARCH: default\n",
      "    ARCH_DEF: \n",
      "    BN_TYPE: bn\n",
      "    DET_HEAD_BLOCKS: []\n",
      "    DET_HEAD_LAST_SCALE: 1.0\n",
      "    DET_HEAD_STRIDE: 0\n",
      "    DW_CONV_SKIP_BN: True\n",
      "    DW_CONV_SKIP_RELU: True\n",
      "    KPTS_HEAD_BLOCKS: []\n",
      "    KPTS_HEAD_LAST_SCALE: 0.0\n",
      "    KPTS_HEAD_STRIDE: 0\n",
      "    MASK_HEAD_BLOCKS: []\n",
      "    MASK_HEAD_LAST_SCALE: 0.0\n",
      "    MASK_HEAD_STRIDE: 0\n",
      "    RPN_BN_TYPE: \n",
      "    RPN_HEAD_BLOCKS: 0\n",
      "    SCALE_FACTOR: 1.0\n",
      "    WIDTH_DIVISOR: 1\n",
      "  FPN:\n",
      "    USE_GN: False\n",
      "    USE_RELU: False\n",
      "  FREQ_PRIOR: visualgenome/label_danfeiX_clipped.freq_prior.npy\n",
      "  GROUP_NORM:\n",
      "    DIM_PER_GP: -1\n",
      "    EPSILON: 1e-05\n",
      "    NUM_GROUPS: 32\n",
      "  KEYPOINT_ON: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: AttrRCNN\n",
      "  RELATION_ON: False\n",
      "  RESNETS:\n",
      "    BACKBONE_OUT_CHANNELS: 1024\n",
      "    DEFORMABLE_GROUPS: 1\n",
      "    NUM_GROUPS: 32\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STAGE_WITH_DCN: (False, False, False, False)\n",
      "    STEM_FUNC: StemWithFixedBatchNorm\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: False\n",
      "    TRANS_FUNC: BottleneckWithFixedBatchNorm\n",
      "    WIDTH_PER_GROUP: 8\n",
      "    WITH_MODULATED_DCN: False\n",
      "  RETINANET:\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDES: (8, 16, 32, 64, 128)\n",
      "    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n",
      "    BBOX_REG_BETA: 0.11\n",
      "    BBOX_REG_WEIGHT: 4.0\n",
      "    BG_IOU_THRESHOLD: 0.4\n",
      "    FG_IOU_THRESHOLD: 0.5\n",
      "    INFERENCE_TH: 0.05\n",
      "    LOSS_ALPHA: 0.25\n",
      "    LOSS_GAMMA: 2.0\n",
      "    NMS_TH: 0.4\n",
      "    NUM_CLASSES: 81\n",
      "    NUM_CONVS: 4\n",
      "    OCTAVE: 2.0\n",
      "    PRE_NMS_TOP_N: 1000\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCALES_PER_OCTAVE: 3\n",
      "    STRADDLE_THRESH: 0\n",
      "    USE_C5: True\n",
      "  RETINANET_ON: False\n",
      "  ROI_ATTRIBUTE_HEAD:\n",
      "    ATTR_EMD_DIM: 512\n",
      "    CLS_EMD_DIM: 256\n",
      "    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor\n",
      "    LOSS_WEIGHT: 0.5\n",
      "    MAX_NUM_ATTR_PER_IMG: 100\n",
      "    MAX_NUM_ATTR_PER_OBJ: 16\n",
      "    MLP_HEAD_DIM: 1024\n",
      "    NUM_ATTRIBUTES: 525\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_SCALES: (0.0625,)\n",
      "    POSTPROCESS_ATTRIBUTES_THRESHOLD: 0.05\n",
      "    PREDICTOR: AttributeRCNNPredictor\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "  ROI_BOX_HEAD:\n",
      "    CONV_HEAD_DIM: 256\n",
      "    DILATION: 1\n",
      "    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor\n",
      "    FORCE_BOXES: False\n",
      "    MLP_HEAD_DIM: 1024\n",
      "    NUM_CLASSES: 1595\n",
      "    NUM_STACKED_CONVS: 4\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_SCALES: (0.0625,)\n",
      "    PREDICTOR: FastRCNNPredictor\n",
      "    USE_GN: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 384\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    BG_IOU_THRESHOLD: 0.5\n",
      "    DETECTIONS_PER_IMG: 100\n",
      "    FG_IOU_THRESHOLD: 0.5\n",
      "    MIN_DETECTIONS_PER_IMG: 10\n",
      "    NMS: 0.5\n",
      "    NMS_FILTER: 1\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    SCORE_THRESH: 0.2\n",
      "    USE_FPN: False\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor\n",
      "    MLP_HEAD_DIM: 1024\n",
      "    NUM_CLASSES: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_SCALES: (0.0625,)\n",
      "    PREDICTOR: KeypointRCNNPredictor\n",
      "    RESOLUTION: 14\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "  ROI_MASK_HEAD:\n",
      "    CONV_LAYERS: (256, 256, 256, 256)\n",
      "    DILATION: 1\n",
      "    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor\n",
      "    MLP_HEAD_DIM: 1024\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_SCALES: (0.0625,)\n",
      "    POSTPROCESS_MASKS: False\n",
      "    POSTPROCESS_MASKS_THRESHOLD: 0.5\n",
      "    PREDICTOR: MaskRCNNC4Predictor\n",
      "    RESOLUTION: 14\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "    USE_GN: False\n",
      "  ROI_RELATION_HEAD:\n",
      "    ALGORITHM: sg_baseline\n",
      "    BACKBONE_FREEZE_PARAMETER: True\n",
      "    BATCH_SIZE_PER_IMAGE: 512\n",
      "    CONCATENATE_PROPOSAL_GT: False\n",
      "    CONTRASTIVE_LOSS:\n",
      "      BG_THRESH_HI: 0.5\n",
      "      BG_THRESH_LO: 0.0\n",
      "      FG_REL_FRACTION: 0.25\n",
      "      FG_REL_SIZE_PER_IM: 512\n",
      "      FG_THRESH: 0.5\n",
      "      NODE_CONTRASTIVE_MARGIN: 0.2\n",
      "      NODE_CONTRASTIVE_P_AWARE_MARGIN: 0.2\n",
      "      NODE_CONTRASTIVE_P_AWARE_WEIGHT: 0.1\n",
      "      NODE_CONTRASTIVE_SO_AWARE_MARGIN: 0.2\n",
      "      NODE_CONTRASTIVE_SO_AWARE_WEIGHT: 0.5\n",
      "      NODE_CONTRASTIVE_WEIGHT: 1.0\n",
      "      NODE_SAMPLE_SIZE: 128\n",
      "      USE_BG: True\n",
      "      USE_FLAG: False\n",
      "      USE_FREQ_BIAS: True\n",
      "      USE_NODE_CONTRASTIVE_LOSS: True\n",
      "      USE_NODE_CONTRASTIVE_P_AWARE_LOSS: True\n",
      "      USE_NODE_CONTRASTIVE_SO_AWARE_LOSS: True\n",
      "      USE_SPATIAL_FEAT: False\n",
      "      USE_SPO_AGNOSTIC_COMPENSATION: False\n",
      "    CONV_HEAD_DIM: 256\n",
      "    DETECTOR_BOX_THRESHOLD: 0.0\n",
      "    DETECTOR_PRE_CALCULATED: False\n",
      "    DILATION: 1\n",
      "    FEATURE_EXTRACTOR: ResNet50Conv5ROIRelationFeatureExtractor\n",
      "    FILTER_NON_OVERLAP: True\n",
      "    FORCE_RELATIONS: False\n",
      "    GRCNN_FEATURE_UPDATE_STEP: 0\n",
      "    GRCNN_SCORE_UPDATE_STEP: 0\n",
      "    IMP_FEATURE_UPDATE_STEP: 0\n",
      "    MLP_HEAD_DIM: 1024\n",
      "    MODE: sgdet\n",
      "    MSDN_FEATURE_UPDATE_STEP: 0\n",
      "    NEURAL_MOTIF:\n",
      "      DEBUG: False\n",
      "      DROPOUT: 0.0\n",
      "      EDGE_LSTM_NUM_LAYERS: 4\n",
      "      EMBED_DIM: 100\n",
      "      GLOVE_PATH: glove/\n",
      "      HIDDEN_DIM: 256\n",
      "      NUM_OBJS: 64\n",
      "      OBJ_CLASSES_FN: visualgenome/label_danfeiX_clipped.obj_classes.txt\n",
      "      OBJ_FEAT_TO_DECODER: False\n",
      "      OBJ_FEAT_TO_EDGE: False\n",
      "      OBJ_LSTM_NUM_LAYERS: 2\n",
      "      ORDER: confidence\n",
      "      POS_BATCHNORM_MOMENTUM: 0.001\n",
      "      POS_EMBED_DIM: 128\n",
      "      REL_CLASSES_FN: visualgenome/label_danfeiX_clipped.rel_classes.txt\n",
      "      USE_TANH: False\n",
      "    NUM_CLASSES: 51\n",
      "    NUM_STACKED_CONVS: 4\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_SCALES: (0.0625,)\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    POSTPROCESS_METHOD: constrained\n",
      "    POSTPROCESS_SCORE_THRESH: 1e-05\n",
      "    POST_RELPN_PREPOSALS: 512\n",
      "    PREDICTOR: FastRCNNRelationPredictor\n",
      "    ROI_BOX_HEAD_FREEZE_PARAMETER: True\n",
      "    RPN_FREEZE_PARAMETER: True\n",
      "    SEPERATE_SO_FEATURE_EXTRACTOR: False\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "    SHARE_CONV_BACKBONE: True\n",
      "    TRIPLETS_PER_IMG: 100\n",
      "    UPDATE_BOX_REG: False\n",
      "    USE_BIAS: False\n",
      "    USE_GN: False\n",
      "    USE_ONLINE_OBJ_LABELS: False\n",
      "    USE_RELPN: False\n",
      "  RPN:\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDE: (16,)\n",
      "    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    FG_IOU_THRESHOLD: 0.7\n",
      "    FORCE_BOXES: False\n",
      "    FPN_POST_NMS_PER_BATCH: True\n",
      "    FPN_POST_NMS_TOP_N_TEST: 2000\n",
      "    FPN_POST_NMS_TOP_N_TRAIN: 2000\n",
      "    MIN_SIZE: 0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOP_N_TEST: 300\n",
      "    POST_NMS_TOP_N_TRAIN: 2000\n",
      "    PRE_NMS_TOP_N_TEST: 6000\n",
      "    PRE_NMS_TOP_N_TRAIN: 12000\n",
      "    RPN_HEAD: SingleConvRPNHead\n",
      "    STRADDLE_THRESH: 0\n",
      "    USE_FPN: False\n",
      "  RPN_ONLY: False\n",
      "  TRANSFORMER:\n",
      "    AVG_POOL: False\n",
      "    DROP: 0.0\n",
      "    DROP_PATH: 0.1\n",
      "    MSVIT:\n",
      "      ARCH: l1,h3,d96,n1,s1,g1,p4,f7,a0_l2,h3,d192,n2,s1,g1,p2,f7,a0_l3,h6,d384,n8,s1,g1,p2,f7,a0_l4,h12,d768,n1,s1,g0,p2,f7,a0\n",
      "      ATTN_TYPE: longformerhand\n",
      "      LN_EPS: 1e-06\n",
      "      MODE: 0\n",
      "      ONLY_GLOBAL: False\n",
      "      REDRAW_INTERVAL: 1000\n",
      "      SHARE_KV: True\n",
      "      SHARE_W: True\n",
      "      SW_EXACT: 0\n",
      "    NORM_EMBED: True\n",
      "    OUT_FEATURES: []\n",
      "    VITHEADARCH: l4,h12,d768,n1,s0,g0,p2,f7,a0\n",
      "  USE_FREQ_PRIOR: False\n",
      "  WEIGHT: pretrained_model/vinvl_vg_x152c4.pth\n",
      "OUTPUT_DIR: output/CIFAR-100\n",
      "PATHS_CATALOG: /nobackup-fast/ziyangc/scene_graph_benchmark/maskrcnn_benchmark/config/paths_catalog.py\n",
      "SOLVER:\n",
      "  BASE_LR: 0.01\n",
      "  BIAS_LR_FACTOR: 2\n",
      "  CHECKPOINT_PERIOD: 10000\n",
      "  CLIP_GRADIENTS:\n",
      "    CLIP_TYPE: full_model\n",
      "    CLIP_VALUE: 1.0\n",
      "    ENABLED: False\n",
      "    NORM_TYPE: 2.0\n",
      "  GAMMA: 0.1\n",
      "  IMS_PER_BATCH: 1\n",
      "  MAX_ITER: 90000\n",
      "  MOMENTUM: 0.9\n",
      "  OPTIMIZER: SGD\n",
      "  STEPS: (49000, 65000)\n",
      "  TEST_PERIOD: 0\n",
      "  USE_AMP: False\n",
      "  WARMUP_FACTOR: 0.3333333333333333\n",
      "  WARMUP_ITERS: 500\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0\n",
      "TEST:\n",
      "  BBOX_AUG:\n",
      "    ENABLED: False\n",
      "    H_FLIP: False\n",
      "    MAX_SIZE: 4000\n",
      "    SCALES: ()\n",
      "    SCALE_H_FLIP: False\n",
      "  DETECTIONS_PER_IMG: 100\n",
      "  EXPECTED_RESULTS: []\n",
      "  EXPECTED_RESULTS_SIGMA_TOL: 4\n",
      "  GATHER_ON_CPU: True\n",
      "  IGNORE_BOX_REGRESSION: True\n",
      "  IMS_PER_BATCH: 2\n",
      "  OUTPUT_ATTRIBUTE_FEATURE: False\n",
      "  OUTPUT_FEATURE: True\n",
      "  OUTPUT_RELATION_FEATURE: False\n",
      "  SAVE_PREDICTIONS: True\n",
      "  SAVE_RESULTS_TO_TSV: True\n",
      "  SKIP_PERFORMANCE_EVAL: True\n",
      "  TSV_SAVE_SUBSET: ['rect', 'class', 'conf', 'feature']\n",
      "2022-04-02 12:03:30,394 maskrcnn_benchmark INFO: Collecting env info (might take some time)\n",
      "2022-04-02 12:03:45,906 maskrcnn_benchmark INFO: \n",
      "PyTorch version: 1.7.1+cu101\n",
      "Is debug build: False\n",
      "CUDA used to build PyTorch: 10.1\n",
      "ROCM used to build PyTorch: N/A\n",
      "\n",
      "OS: Ubuntu 20.04.4 LTS (x86_64)\n",
      "GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
      "Clang version: 8.0.0 (trunk 340542)\n",
      "CMake version: version 3.23.0\n",
      "\n",
      "Python version: 3.7 (64-bit runtime)\n",
      "Is CUDA available: True\n",
      "CUDA runtime version: Could not collect\n",
      "GPU models and configuration: \n",
      "GPU 0: NVIDIA GeForce RTX 2080 Ti\n",
      "GPU 1: NVIDIA GeForce RTX 2080 Ti\n",
      "GPU 2: NVIDIA GeForce RTX 2080 Ti\n",
      "GPU 3: NVIDIA GeForce RTX 2080 Ti\n",
      "GPU 4: NVIDIA GeForce RTX 2080 Ti\n",
      "GPU 5: NVIDIA GeForce RTX 2080 Ti\n",
      "GPU 6: NVIDIA GeForce RTX 2080 Ti\n",
      "GPU 7: NVIDIA GeForce RTX 2080 Ti\n",
      "\n",
      "Nvidia driver version: 510.47.03\n",
      "cuDNN version: Probably one of the following:\n",
      "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.3.3\n",
      "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.3.3\n",
      "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.3.3\n",
      "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.3.3\n",
      "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.3.3\n",
      "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.3.3\n",
      "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.3.3\n",
      "HIP runtime version: N/A\n",
      "MIOpen runtime version: N/A\n",
      "\n",
      "Versions of relevant libraries:\n",
      "[pip3] numpy==1.21.5\n",
      "[pip3] pytorch-transformers==1.0.0\n",
      "[pip3] torch==1.7.1+cu101\n",
      "[pip3] torchaudio==0.7.2\n",
      "[pip3] torchvision==0.8.2+cu101\n",
      "[conda] cudatoolkit               11.3.1               ha36c431_9    nvidia\n",
      "[conda] nomkl                     1.0                  h5ca1d4c_0    conda-forge\n",
      "[conda] numpy                     1.21.5           py37hf2998dd_0    conda-forge\n",
      "[conda] pytorch-transformers      1.0.0                    pypi_0    pypi\n",
      "[conda] torch                     1.7.1+cu101              pypi_0    pypi\n",
      "[conda] torchaudio                0.7.2                    pypi_0    pypi\n",
      "[conda] torchvision               0.8.2+cu101              pypi_0    pypi\n",
      "        Pillow (9.0.1)\n",
      "2022-04-02 12:03:53,296 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from pretrained_model/vinvl_vg_x152c4.pth\n",
      "2022-04-02 12:03:53,951 maskrcnn_benchmark.utils.model_serialization INFO: Parameters not initialized from checkpoint: \n",
      "\n",
      "2022-04-02 12:03:53,951 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.0.bn1.bias                      loaded from attribute.feature_extractor.head.layer4.0.bn1.bias                      of shape (2048,)\n",
      "2022-04-02 12:03:53,951 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.0.bn1.running_mean              loaded from attribute.feature_extractor.head.layer4.0.bn1.running_mean              of shape (2048,)\n",
      "2022-04-02 12:03:53,951 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.0.bn1.running_var               loaded from attribute.feature_extractor.head.layer4.0.bn1.running_var               of shape (2048,)\n",
      "2022-04-02 12:03:53,951 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.0.bn1.weight                    loaded from attribute.feature_extractor.head.layer4.0.bn1.weight                    of shape (2048,)\n",
      "2022-04-02 12:03:53,951 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.0.bn2.bias                      loaded from attribute.feature_extractor.head.layer4.0.bn2.bias                      of shape (2048,)\n",
      "2022-04-02 12:03:53,951 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.0.bn2.running_mean              loaded from attribute.feature_extractor.head.layer4.0.bn2.running_mean              of shape (2048,)\n",
      "2022-04-02 12:03:53,951 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.0.bn2.running_var               loaded from attribute.feature_extractor.head.layer4.0.bn2.running_var               of shape (2048,)\n",
      "2022-04-02 12:03:53,951 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.0.bn2.weight                    loaded from attribute.feature_extractor.head.layer4.0.bn2.weight                    of shape (2048,)\n",
      "2022-04-02 12:03:53,951 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.0.bn3.bias                      loaded from attribute.feature_extractor.head.layer4.0.bn3.bias                      of shape (2048,)\n",
      "2022-04-02 12:03:53,951 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.0.bn3.running_mean              loaded from attribute.feature_extractor.head.layer4.0.bn3.running_mean              of shape (2048,)\n",
      "2022-04-02 12:03:53,951 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.0.bn3.running_var               loaded from attribute.feature_extractor.head.layer4.0.bn3.running_var               of shape (2048,)\n",
      "2022-04-02 12:03:53,951 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.0.bn3.weight                    loaded from attribute.feature_extractor.head.layer4.0.bn3.weight                    of shape (2048,)\n",
      "2022-04-02 12:03:53,951 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.0.conv1.weight                  loaded from attribute.feature_extractor.head.layer4.0.conv1.weight                  of shape (2048, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,952 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.0.conv2.weight                  loaded from attribute.feature_extractor.head.layer4.0.conv2.weight                  of shape (2048, 64, 3, 3)\n",
      "2022-04-02 12:03:53,952 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.0.conv3.weight                  loaded from attribute.feature_extractor.head.layer4.0.conv3.weight                  of shape (2048, 2048, 1, 1)\n",
      "2022-04-02 12:03:53,952 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.0.downsample.0.weight           loaded from attribute.feature_extractor.head.layer4.0.downsample.0.weight           of shape (2048, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,952 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.0.downsample.1.bias             loaded from attribute.feature_extractor.head.layer4.0.downsample.1.bias             of shape (2048,)\n",
      "2022-04-02 12:03:53,952 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.0.downsample.1.running_mean     loaded from attribute.feature_extractor.head.layer4.0.downsample.1.running_mean     of shape (2048,)\n",
      "2022-04-02 12:03:53,952 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.0.downsample.1.running_var      loaded from attribute.feature_extractor.head.layer4.0.downsample.1.running_var      of shape (2048,)\n",
      "2022-04-02 12:03:53,952 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.0.downsample.1.weight           loaded from attribute.feature_extractor.head.layer4.0.downsample.1.weight           of shape (2048,)\n",
      "2022-04-02 12:03:53,952 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.1.bn1.bias                      loaded from attribute.feature_extractor.head.layer4.1.bn1.bias                      of shape (2048,)\n",
      "2022-04-02 12:03:53,952 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.1.bn1.running_mean              loaded from attribute.feature_extractor.head.layer4.1.bn1.running_mean              of shape (2048,)\n",
      "2022-04-02 12:03:53,952 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.1.bn1.running_var               loaded from attribute.feature_extractor.head.layer4.1.bn1.running_var               of shape (2048,)\n",
      "2022-04-02 12:03:53,952 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.1.bn1.weight                    loaded from attribute.feature_extractor.head.layer4.1.bn1.weight                    of shape (2048,)\n",
      "2022-04-02 12:03:53,952 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.1.bn2.bias                      loaded from attribute.feature_extractor.head.layer4.1.bn2.bias                      of shape (2048,)\n",
      "2022-04-02 12:03:53,952 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.1.bn2.running_mean              loaded from attribute.feature_extractor.head.layer4.1.bn2.running_mean              of shape (2048,)\n",
      "2022-04-02 12:03:53,952 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.1.bn2.running_var               loaded from attribute.feature_extractor.head.layer4.1.bn2.running_var               of shape (2048,)\n",
      "2022-04-02 12:03:53,952 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.1.bn2.weight                    loaded from attribute.feature_extractor.head.layer4.1.bn2.weight                    of shape (2048,)\n",
      "2022-04-02 12:03:53,952 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.1.bn3.bias                      loaded from attribute.feature_extractor.head.layer4.1.bn3.bias                      of shape (2048,)\n",
      "2022-04-02 12:03:53,952 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.1.bn3.running_mean              loaded from attribute.feature_extractor.head.layer4.1.bn3.running_mean              of shape (2048,)\n",
      "2022-04-02 12:03:53,952 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.1.bn3.running_var               loaded from attribute.feature_extractor.head.layer4.1.bn3.running_var               of shape (2048,)\n",
      "2022-04-02 12:03:53,952 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.1.bn3.weight                    loaded from attribute.feature_extractor.head.layer4.1.bn3.weight                    of shape (2048,)\n",
      "2022-04-02 12:03:53,952 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.1.conv1.weight                  loaded from attribute.feature_extractor.head.layer4.1.conv1.weight                  of shape (2048, 2048, 1, 1)\n",
      "2022-04-02 12:03:53,952 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.1.conv2.weight                  loaded from attribute.feature_extractor.head.layer4.1.conv2.weight                  of shape (2048, 64, 3, 3)\n",
      "2022-04-02 12:03:53,953 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.1.conv3.weight                  loaded from attribute.feature_extractor.head.layer4.1.conv3.weight                  of shape (2048, 2048, 1, 1)\n",
      "2022-04-02 12:03:53,953 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.2.bn1.bias                      loaded from attribute.feature_extractor.head.layer4.2.bn1.bias                      of shape (2048,)\n",
      "2022-04-02 12:03:53,953 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.2.bn1.running_mean              loaded from attribute.feature_extractor.head.layer4.2.bn1.running_mean              of shape (2048,)\n",
      "2022-04-02 12:03:53,953 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.2.bn1.running_var               loaded from attribute.feature_extractor.head.layer4.2.bn1.running_var               of shape (2048,)\n",
      "2022-04-02 12:03:53,953 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.2.bn1.weight                    loaded from attribute.feature_extractor.head.layer4.2.bn1.weight                    of shape (2048,)\n",
      "2022-04-02 12:03:53,953 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.2.bn2.bias                      loaded from attribute.feature_extractor.head.layer4.2.bn2.bias                      of shape (2048,)\n",
      "2022-04-02 12:03:53,953 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.2.bn2.running_mean              loaded from attribute.feature_extractor.head.layer4.2.bn2.running_mean              of shape (2048,)\n",
      "2022-04-02 12:03:53,953 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.2.bn2.running_var               loaded from attribute.feature_extractor.head.layer4.2.bn2.running_var               of shape (2048,)\n",
      "2022-04-02 12:03:53,953 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.2.bn2.weight                    loaded from attribute.feature_extractor.head.layer4.2.bn2.weight                    of shape (2048,)\n",
      "2022-04-02 12:03:53,953 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.2.bn3.bias                      loaded from attribute.feature_extractor.head.layer4.2.bn3.bias                      of shape (2048,)\n",
      "2022-04-02 12:03:53,953 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.2.bn3.running_mean              loaded from attribute.feature_extractor.head.layer4.2.bn3.running_mean              of shape (2048,)\n",
      "2022-04-02 12:03:53,953 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.2.bn3.running_var               loaded from attribute.feature_extractor.head.layer4.2.bn3.running_var               of shape (2048,)\n",
      "2022-04-02 12:03:53,953 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.2.bn3.weight                    loaded from attribute.feature_extractor.head.layer4.2.bn3.weight                    of shape (2048,)\n",
      "2022-04-02 12:03:53,953 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.2.conv1.weight                  loaded from attribute.feature_extractor.head.layer4.2.conv1.weight                  of shape (2048, 2048, 1, 1)\n",
      "2022-04-02 12:03:53,953 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.2.conv2.weight                  loaded from attribute.feature_extractor.head.layer4.2.conv2.weight                  of shape (2048, 64, 3, 3)\n",
      "2022-04-02 12:03:53,953 maskrcnn_benchmark.utils.model_serialization INFO: attribute.feature_extractor.head.layer4.2.conv3.weight                  loaded from attribute.feature_extractor.head.layer4.2.conv3.weight                  of shape (2048, 2048, 1, 1)\n",
      "2022-04-02 12:03:53,953 maskrcnn_benchmark.utils.model_serialization INFO: attribute.predictor.attr_score.bias                                     loaded from attribute.predictor.attr_score.bias                                     of shape (525,)\n",
      "2022-04-02 12:03:53,953 maskrcnn_benchmark.utils.model_serialization INFO: attribute.predictor.attr_score.weight                                   loaded from attribute.predictor.attr_score.weight                                   of shape (525, 512)\n",
      "2022-04-02 12:03:53,953 maskrcnn_benchmark.utils.model_serialization INFO: attribute.predictor.cls_embedding.weight                                loaded from attribute.predictor.cls_embedding.weight                                of shape (1595, 256)\n",
      "2022-04-02 12:03:53,953 maskrcnn_benchmark.utils.model_serialization INFO: attribute.predictor.fc_attr.bias                                        loaded from attribute.predictor.fc_attr.bias                                        of shape (512,)\n",
      "2022-04-02 12:03:53,954 maskrcnn_benchmark.utils.model_serialization INFO: attribute.predictor.fc_attr.weight                                      loaded from attribute.predictor.fc_attr.weight                                      of shape (512, 2304)\n",
      "2022-04-02 12:03:53,954 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.bias                                         loaded from backbone.body.layer1.0.bn1.bias                                         of shape (256,)\n",
      "2022-04-02 12:03:53,954 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.running_mean                                 loaded from backbone.body.layer1.0.bn1.running_mean                                 of shape (256,)\n",
      "2022-04-02 12:03:53,954 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.running_var                                  loaded from backbone.body.layer1.0.bn1.running_var                                  of shape (256,)\n",
      "2022-04-02 12:03:53,954 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.weight                                       loaded from backbone.body.layer1.0.bn1.weight                                       of shape (256,)\n",
      "2022-04-02 12:03:53,954 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.bias                                         loaded from backbone.body.layer1.0.bn2.bias                                         of shape (256,)\n",
      "2022-04-02 12:03:53,954 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.running_mean                                 loaded from backbone.body.layer1.0.bn2.running_mean                                 of shape (256,)\n",
      "2022-04-02 12:03:53,954 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.running_var                                  loaded from backbone.body.layer1.0.bn2.running_var                                  of shape (256,)\n",
      "2022-04-02 12:03:53,954 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.weight                                       loaded from backbone.body.layer1.0.bn2.weight                                       of shape (256,)\n",
      "2022-04-02 12:03:53,954 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.bias                                         loaded from backbone.body.layer1.0.bn3.bias                                         of shape (256,)\n",
      "2022-04-02 12:03:53,954 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.running_mean                                 loaded from backbone.body.layer1.0.bn3.running_mean                                 of shape (256,)\n",
      "2022-04-02 12:03:53,954 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.running_var                                  loaded from backbone.body.layer1.0.bn3.running_var                                  of shape (256,)\n",
      "2022-04-02 12:03:53,954 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.weight                                       loaded from backbone.body.layer1.0.bn3.weight                                       of shape (256,)\n",
      "2022-04-02 12:03:53,954 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv1.weight                                     loaded from backbone.body.layer1.0.conv1.weight                                     of shape (256, 64, 1, 1)\n",
      "2022-04-02 12:03:53,954 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv2.weight                                     loaded from backbone.body.layer1.0.conv2.weight                                     of shape (256, 8, 3, 3)\n",
      "2022-04-02 12:03:53,954 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv3.weight                                     loaded from backbone.body.layer1.0.conv3.weight                                     of shape (256, 256, 1, 1)\n",
      "2022-04-02 12:03:53,954 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.0.weight                              loaded from backbone.body.layer1.0.downsample.0.weight                              of shape (256, 64, 1, 1)\n",
      "2022-04-02 12:03:53,954 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.bias                                loaded from backbone.body.layer1.0.downsample.1.bias                                of shape (256,)\n",
      "2022-04-02 12:03:53,954 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.running_mean                        loaded from backbone.body.layer1.0.downsample.1.running_mean                        of shape (256,)\n",
      "2022-04-02 12:03:53,954 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.running_var                         loaded from backbone.body.layer1.0.downsample.1.running_var                         of shape (256,)\n",
      "2022-04-02 12:03:53,954 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.weight                              loaded from backbone.body.layer1.0.downsample.1.weight                              of shape (256,)\n",
      "2022-04-02 12:03:53,955 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.bias                                         loaded from backbone.body.layer1.1.bn1.bias                                         of shape (256,)\n",
      "2022-04-02 12:03:53,955 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.running_mean                                 loaded from backbone.body.layer1.1.bn1.running_mean                                 of shape (256,)\n",
      "2022-04-02 12:03:53,955 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.running_var                                  loaded from backbone.body.layer1.1.bn1.running_var                                  of shape (256,)\n",
      "2022-04-02 12:03:53,955 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.weight                                       loaded from backbone.body.layer1.1.bn1.weight                                       of shape (256,)\n",
      "2022-04-02 12:03:53,955 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.bias                                         loaded from backbone.body.layer1.1.bn2.bias                                         of shape (256,)\n",
      "2022-04-02 12:03:53,955 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.running_mean                                 loaded from backbone.body.layer1.1.bn2.running_mean                                 of shape (256,)\n",
      "2022-04-02 12:03:53,955 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.running_var                                  loaded from backbone.body.layer1.1.bn2.running_var                                  of shape (256,)\n",
      "2022-04-02 12:03:53,955 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.weight                                       loaded from backbone.body.layer1.1.bn2.weight                                       of shape (256,)\n",
      "2022-04-02 12:03:53,955 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.bias                                         loaded from backbone.body.layer1.1.bn3.bias                                         of shape (256,)\n",
      "2022-04-02 12:03:53,955 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.running_mean                                 loaded from backbone.body.layer1.1.bn3.running_mean                                 of shape (256,)\n",
      "2022-04-02 12:03:53,955 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.running_var                                  loaded from backbone.body.layer1.1.bn3.running_var                                  of shape (256,)\n",
      "2022-04-02 12:03:53,955 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.weight                                       loaded from backbone.body.layer1.1.bn3.weight                                       of shape (256,)\n",
      "2022-04-02 12:03:53,955 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv1.weight                                     loaded from backbone.body.layer1.1.conv1.weight                                     of shape (256, 256, 1, 1)\n",
      "2022-04-02 12:03:53,955 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv2.weight                                     loaded from backbone.body.layer1.1.conv2.weight                                     of shape (256, 8, 3, 3)\n",
      "2022-04-02 12:03:53,955 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv3.weight                                     loaded from backbone.body.layer1.1.conv3.weight                                     of shape (256, 256, 1, 1)\n",
      "2022-04-02 12:03:53,955 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.bias                                         loaded from backbone.body.layer1.2.bn1.bias                                         of shape (256,)\n",
      "2022-04-02 12:03:53,955 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.running_mean                                 loaded from backbone.body.layer1.2.bn1.running_mean                                 of shape (256,)\n",
      "2022-04-02 12:03:53,955 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.running_var                                  loaded from backbone.body.layer1.2.bn1.running_var                                  of shape (256,)\n",
      "2022-04-02 12:03:53,955 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.weight                                       loaded from backbone.body.layer1.2.bn1.weight                                       of shape (256,)\n",
      "2022-04-02 12:03:53,955 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.bias                                         loaded from backbone.body.layer1.2.bn2.bias                                         of shape (256,)\n",
      "2022-04-02 12:03:53,955 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.running_mean                                 loaded from backbone.body.layer1.2.bn2.running_mean                                 of shape (256,)\n",
      "2022-04-02 12:03:53,956 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.running_var                                  loaded from backbone.body.layer1.2.bn2.running_var                                  of shape (256,)\n",
      "2022-04-02 12:03:53,956 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.weight                                       loaded from backbone.body.layer1.2.bn2.weight                                       of shape (256,)\n",
      "2022-04-02 12:03:53,956 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.bias                                         loaded from backbone.body.layer1.2.bn3.bias                                         of shape (256,)\n",
      "2022-04-02 12:03:53,956 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.running_mean                                 loaded from backbone.body.layer1.2.bn3.running_mean                                 of shape (256,)\n",
      "2022-04-02 12:03:53,956 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.running_var                                  loaded from backbone.body.layer1.2.bn3.running_var                                  of shape (256,)\n",
      "2022-04-02 12:03:53,956 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.weight                                       loaded from backbone.body.layer1.2.bn3.weight                                       of shape (256,)\n",
      "2022-04-02 12:03:53,956 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv1.weight                                     loaded from backbone.body.layer1.2.conv1.weight                                     of shape (256, 256, 1, 1)\n",
      "2022-04-02 12:03:53,956 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv2.weight                                     loaded from backbone.body.layer1.2.conv2.weight                                     of shape (256, 8, 3, 3)\n",
      "2022-04-02 12:03:53,956 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv3.weight                                     loaded from backbone.body.layer1.2.conv3.weight                                     of shape (256, 256, 1, 1)\n",
      "2022-04-02 12:03:53,956 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.bias                                         loaded from backbone.body.layer2.0.bn1.bias                                         of shape (512,)\n",
      "2022-04-02 12:03:53,956 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.running_mean                                 loaded from backbone.body.layer2.0.bn1.running_mean                                 of shape (512,)\n",
      "2022-04-02 12:03:53,956 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.running_var                                  loaded from backbone.body.layer2.0.bn1.running_var                                  of shape (512,)\n",
      "2022-04-02 12:03:53,956 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.weight                                       loaded from backbone.body.layer2.0.bn1.weight                                       of shape (512,)\n",
      "2022-04-02 12:03:53,956 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.bias                                         loaded from backbone.body.layer2.0.bn2.bias                                         of shape (512,)\n",
      "2022-04-02 12:03:53,956 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.running_mean                                 loaded from backbone.body.layer2.0.bn2.running_mean                                 of shape (512,)\n",
      "2022-04-02 12:03:53,956 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.running_var                                  loaded from backbone.body.layer2.0.bn2.running_var                                  of shape (512,)\n",
      "2022-04-02 12:03:53,956 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.weight                                       loaded from backbone.body.layer2.0.bn2.weight                                       of shape (512,)\n",
      "2022-04-02 12:03:53,956 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.bias                                         loaded from backbone.body.layer2.0.bn3.bias                                         of shape (512,)\n",
      "2022-04-02 12:03:53,956 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.running_mean                                 loaded from backbone.body.layer2.0.bn3.running_mean                                 of shape (512,)\n",
      "2022-04-02 12:03:53,956 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.running_var                                  loaded from backbone.body.layer2.0.bn3.running_var                                  of shape (512,)\n",
      "2022-04-02 12:03:53,956 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.weight                                       loaded from backbone.body.layer2.0.bn3.weight                                       of shape (512,)\n",
      "2022-04-02 12:03:53,956 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv1.weight                                     loaded from backbone.body.layer2.0.conv1.weight                                     of shape (512, 256, 1, 1)\n",
      "2022-04-02 12:03:53,956 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv2.weight                                     loaded from backbone.body.layer2.0.conv2.weight                                     of shape (512, 16, 3, 3)\n",
      "2022-04-02 12:03:53,956 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv3.weight                                     loaded from backbone.body.layer2.0.conv3.weight                                     of shape (512, 512, 1, 1)\n",
      "2022-04-02 12:03:53,956 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.0.weight                              loaded from backbone.body.layer2.0.downsample.0.weight                              of shape (512, 256, 1, 1)\n",
      "2022-04-02 12:03:53,957 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.bias                                loaded from backbone.body.layer2.0.downsample.1.bias                                of shape (512,)\n",
      "2022-04-02 12:03:53,957 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.running_mean                        loaded from backbone.body.layer2.0.downsample.1.running_mean                        of shape (512,)\n",
      "2022-04-02 12:03:53,957 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.running_var                         loaded from backbone.body.layer2.0.downsample.1.running_var                         of shape (512,)\n",
      "2022-04-02 12:03:53,957 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.weight                              loaded from backbone.body.layer2.0.downsample.1.weight                              of shape (512,)\n",
      "2022-04-02 12:03:53,957 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.bias                                         loaded from backbone.body.layer2.1.bn1.bias                                         of shape (512,)\n",
      "2022-04-02 12:03:53,957 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.running_mean                                 loaded from backbone.body.layer2.1.bn1.running_mean                                 of shape (512,)\n",
      "2022-04-02 12:03:53,957 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.running_var                                  loaded from backbone.body.layer2.1.bn1.running_var                                  of shape (512,)\n",
      "2022-04-02 12:03:53,957 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.weight                                       loaded from backbone.body.layer2.1.bn1.weight                                       of shape (512,)\n",
      "2022-04-02 12:03:53,957 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.bias                                         loaded from backbone.body.layer2.1.bn2.bias                                         of shape (512,)\n",
      "2022-04-02 12:03:53,957 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.running_mean                                 loaded from backbone.body.layer2.1.bn2.running_mean                                 of shape (512,)\n",
      "2022-04-02 12:03:53,957 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.running_var                                  loaded from backbone.body.layer2.1.bn2.running_var                                  of shape (512,)\n",
      "2022-04-02 12:03:53,957 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.weight                                       loaded from backbone.body.layer2.1.bn2.weight                                       of shape (512,)\n",
      "2022-04-02 12:03:53,957 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.bias                                         loaded from backbone.body.layer2.1.bn3.bias                                         of shape (512,)\n",
      "2022-04-02 12:03:53,957 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.running_mean                                 loaded from backbone.body.layer2.1.bn3.running_mean                                 of shape (512,)\n",
      "2022-04-02 12:03:53,957 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.running_var                                  loaded from backbone.body.layer2.1.bn3.running_var                                  of shape (512,)\n",
      "2022-04-02 12:03:53,961 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.weight                                       loaded from backbone.body.layer2.1.bn3.weight                                       of shape (512,)\n",
      "2022-04-02 12:03:53,961 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv1.weight                                     loaded from backbone.body.layer2.1.conv1.weight                                     of shape (512, 512, 1, 1)\n",
      "2022-04-02 12:03:53,961 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv2.weight                                     loaded from backbone.body.layer2.1.conv2.weight                                     of shape (512, 16, 3, 3)\n",
      "2022-04-02 12:03:53,961 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv3.weight                                     loaded from backbone.body.layer2.1.conv3.weight                                     of shape (512, 512, 1, 1)\n",
      "2022-04-02 12:03:53,961 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.bias                                         loaded from backbone.body.layer2.2.bn1.bias                                         of shape (512,)\n",
      "2022-04-02 12:03:53,962 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.running_mean                                 loaded from backbone.body.layer2.2.bn1.running_mean                                 of shape (512,)\n",
      "2022-04-02 12:03:53,962 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.running_var                                  loaded from backbone.body.layer2.2.bn1.running_var                                  of shape (512,)\n",
      "2022-04-02 12:03:53,962 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.weight                                       loaded from backbone.body.layer2.2.bn1.weight                                       of shape (512,)\n",
      "2022-04-02 12:03:53,962 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.bias                                         loaded from backbone.body.layer2.2.bn2.bias                                         of shape (512,)\n",
      "2022-04-02 12:03:53,962 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.running_mean                                 loaded from backbone.body.layer2.2.bn2.running_mean                                 of shape (512,)\n",
      "2022-04-02 12:03:53,962 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.running_var                                  loaded from backbone.body.layer2.2.bn2.running_var                                  of shape (512,)\n",
      "2022-04-02 12:03:53,962 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.weight                                       loaded from backbone.body.layer2.2.bn2.weight                                       of shape (512,)\n",
      "2022-04-02 12:03:53,962 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.bias                                         loaded from backbone.body.layer2.2.bn3.bias                                         of shape (512,)\n",
      "2022-04-02 12:03:53,962 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.running_mean                                 loaded from backbone.body.layer2.2.bn3.running_mean                                 of shape (512,)\n",
      "2022-04-02 12:03:53,962 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.running_var                                  loaded from backbone.body.layer2.2.bn3.running_var                                  of shape (512,)\n",
      "2022-04-02 12:03:53,962 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.weight                                       loaded from backbone.body.layer2.2.bn3.weight                                       of shape (512,)\n",
      "2022-04-02 12:03:53,962 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv1.weight                                     loaded from backbone.body.layer2.2.conv1.weight                                     of shape (512, 512, 1, 1)\n",
      "2022-04-02 12:03:53,962 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv2.weight                                     loaded from backbone.body.layer2.2.conv2.weight                                     of shape (512, 16, 3, 3)\n",
      "2022-04-02 12:03:53,962 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv3.weight                                     loaded from backbone.body.layer2.2.conv3.weight                                     of shape (512, 512, 1, 1)\n",
      "2022-04-02 12:03:53,962 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.bias                                         loaded from backbone.body.layer2.3.bn1.bias                                         of shape (512,)\n",
      "2022-04-02 12:03:53,962 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.running_mean                                 loaded from backbone.body.layer2.3.bn1.running_mean                                 of shape (512,)\n",
      "2022-04-02 12:03:53,962 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.running_var                                  loaded from backbone.body.layer2.3.bn1.running_var                                  of shape (512,)\n",
      "2022-04-02 12:03:53,962 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.weight                                       loaded from backbone.body.layer2.3.bn1.weight                                       of shape (512,)\n",
      "2022-04-02 12:03:53,962 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.bias                                         loaded from backbone.body.layer2.3.bn2.bias                                         of shape (512,)\n",
      "2022-04-02 12:03:53,962 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.running_mean                                 loaded from backbone.body.layer2.3.bn2.running_mean                                 of shape (512,)\n",
      "2022-04-02 12:03:53,962 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.running_var                                  loaded from backbone.body.layer2.3.bn2.running_var                                  of shape (512,)\n",
      "2022-04-02 12:03:53,962 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.weight                                       loaded from backbone.body.layer2.3.bn2.weight                                       of shape (512,)\n",
      "2022-04-02 12:03:53,962 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.bias                                         loaded from backbone.body.layer2.3.bn3.bias                                         of shape (512,)\n",
      "2022-04-02 12:03:53,962 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.running_mean                                 loaded from backbone.body.layer2.3.bn3.running_mean                                 of shape (512,)\n",
      "2022-04-02 12:03:53,962 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.running_var                                  loaded from backbone.body.layer2.3.bn3.running_var                                  of shape (512,)\n",
      "2022-04-02 12:03:53,962 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.weight                                       loaded from backbone.body.layer2.3.bn3.weight                                       of shape (512,)\n",
      "2022-04-02 12:03:53,962 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv1.weight                                     loaded from backbone.body.layer2.3.conv1.weight                                     of shape (512, 512, 1, 1)\n",
      "2022-04-02 12:03:53,962 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv2.weight                                     loaded from backbone.body.layer2.3.conv2.weight                                     of shape (512, 16, 3, 3)\n",
      "2022-04-02 12:03:53,963 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv3.weight                                     loaded from backbone.body.layer2.3.conv3.weight                                     of shape (512, 512, 1, 1)\n",
      "2022-04-02 12:03:53,963 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.4.bn1.bias                                         loaded from backbone.body.layer2.4.bn1.bias                                         of shape (512,)\n",
      "2022-04-02 12:03:53,963 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.4.bn1.running_mean                                 loaded from backbone.body.layer2.4.bn1.running_mean                                 of shape (512,)\n",
      "2022-04-02 12:03:53,963 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.4.bn1.running_var                                  loaded from backbone.body.layer2.4.bn1.running_var                                  of shape (512,)\n",
      "2022-04-02 12:03:53,963 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.4.bn1.weight                                       loaded from backbone.body.layer2.4.bn1.weight                                       of shape (512,)\n",
      "2022-04-02 12:03:53,963 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.4.bn2.bias                                         loaded from backbone.body.layer2.4.bn2.bias                                         of shape (512,)\n",
      "2022-04-02 12:03:53,963 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.4.bn2.running_mean                                 loaded from backbone.body.layer2.4.bn2.running_mean                                 of shape (512,)\n",
      "2022-04-02 12:03:53,963 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.4.bn2.running_var                                  loaded from backbone.body.layer2.4.bn2.running_var                                  of shape (512,)\n",
      "2022-04-02 12:03:53,963 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.4.bn2.weight                                       loaded from backbone.body.layer2.4.bn2.weight                                       of shape (512,)\n",
      "2022-04-02 12:03:53,963 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.4.bn3.bias                                         loaded from backbone.body.layer2.4.bn3.bias                                         of shape (512,)\n",
      "2022-04-02 12:03:53,963 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.4.bn3.running_mean                                 loaded from backbone.body.layer2.4.bn3.running_mean                                 of shape (512,)\n",
      "2022-04-02 12:03:53,963 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.4.bn3.running_var                                  loaded from backbone.body.layer2.4.bn3.running_var                                  of shape (512,)\n",
      "2022-04-02 12:03:53,963 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.4.bn3.weight                                       loaded from backbone.body.layer2.4.bn3.weight                                       of shape (512,)\n",
      "2022-04-02 12:03:53,963 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.4.conv1.weight                                     loaded from backbone.body.layer2.4.conv1.weight                                     of shape (512, 512, 1, 1)\n",
      "2022-04-02 12:03:53,963 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.4.conv2.weight                                     loaded from backbone.body.layer2.4.conv2.weight                                     of shape (512, 16, 3, 3)\n",
      "2022-04-02 12:03:53,963 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.4.conv3.weight                                     loaded from backbone.body.layer2.4.conv3.weight                                     of shape (512, 512, 1, 1)\n",
      "2022-04-02 12:03:53,963 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.5.bn1.bias                                         loaded from backbone.body.layer2.5.bn1.bias                                         of shape (512,)\n",
      "2022-04-02 12:03:53,963 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.5.bn1.running_mean                                 loaded from backbone.body.layer2.5.bn1.running_mean                                 of shape (512,)\n",
      "2022-04-02 12:03:53,963 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.5.bn1.running_var                                  loaded from backbone.body.layer2.5.bn1.running_var                                  of shape (512,)\n",
      "2022-04-02 12:03:53,963 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.5.bn1.weight                                       loaded from backbone.body.layer2.5.bn1.weight                                       of shape (512,)\n",
      "2022-04-02 12:03:53,963 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.5.bn2.bias                                         loaded from backbone.body.layer2.5.bn2.bias                                         of shape (512,)\n",
      "2022-04-02 12:03:53,963 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.5.bn2.running_mean                                 loaded from backbone.body.layer2.5.bn2.running_mean                                 of shape (512,)\n",
      "2022-04-02 12:03:53,963 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.5.bn2.running_var                                  loaded from backbone.body.layer2.5.bn2.running_var                                  of shape (512,)\n",
      "2022-04-02 12:03:53,963 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.5.bn2.weight                                       loaded from backbone.body.layer2.5.bn2.weight                                       of shape (512,)\n",
      "2022-04-02 12:03:53,963 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.5.bn3.bias                                         loaded from backbone.body.layer2.5.bn3.bias                                         of shape (512,)\n",
      "2022-04-02 12:03:53,963 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.5.bn3.running_mean                                 loaded from backbone.body.layer2.5.bn3.running_mean                                 of shape (512,)\n",
      "2022-04-02 12:03:53,963 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.5.bn3.running_var                                  loaded from backbone.body.layer2.5.bn3.running_var                                  of shape (512,)\n",
      "2022-04-02 12:03:53,963 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.5.bn3.weight                                       loaded from backbone.body.layer2.5.bn3.weight                                       of shape (512,)\n",
      "2022-04-02 12:03:53,963 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.5.conv1.weight                                     loaded from backbone.body.layer2.5.conv1.weight                                     of shape (512, 512, 1, 1)\n",
      "2022-04-02 12:03:53,964 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.5.conv2.weight                                     loaded from backbone.body.layer2.5.conv2.weight                                     of shape (512, 16, 3, 3)\n",
      "2022-04-02 12:03:53,964 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.5.conv3.weight                                     loaded from backbone.body.layer2.5.conv3.weight                                     of shape (512, 512, 1, 1)\n",
      "2022-04-02 12:03:53,964 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.6.bn1.bias                                         loaded from backbone.body.layer2.6.bn1.bias                                         of shape (512,)\n",
      "2022-04-02 12:03:53,964 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.6.bn1.running_mean                                 loaded from backbone.body.layer2.6.bn1.running_mean                                 of shape (512,)\n",
      "2022-04-02 12:03:53,964 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.6.bn1.running_var                                  loaded from backbone.body.layer2.6.bn1.running_var                                  of shape (512,)\n",
      "2022-04-02 12:03:53,964 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.6.bn1.weight                                       loaded from backbone.body.layer2.6.bn1.weight                                       of shape (512,)\n",
      "2022-04-02 12:03:53,964 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.6.bn2.bias                                         loaded from backbone.body.layer2.6.bn2.bias                                         of shape (512,)\n",
      "2022-04-02 12:03:53,964 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.6.bn2.running_mean                                 loaded from backbone.body.layer2.6.bn2.running_mean                                 of shape (512,)\n",
      "2022-04-02 12:03:53,964 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.6.bn2.running_var                                  loaded from backbone.body.layer2.6.bn2.running_var                                  of shape (512,)\n",
      "2022-04-02 12:03:53,964 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.6.bn2.weight                                       loaded from backbone.body.layer2.6.bn2.weight                                       of shape (512,)\n",
      "2022-04-02 12:03:53,964 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.6.bn3.bias                                         loaded from backbone.body.layer2.6.bn3.bias                                         of shape (512,)\n",
      "2022-04-02 12:03:53,964 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.6.bn3.running_mean                                 loaded from backbone.body.layer2.6.bn3.running_mean                                 of shape (512,)\n",
      "2022-04-02 12:03:53,964 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.6.bn3.running_var                                  loaded from backbone.body.layer2.6.bn3.running_var                                  of shape (512,)\n",
      "2022-04-02 12:03:53,964 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.6.bn3.weight                                       loaded from backbone.body.layer2.6.bn3.weight                                       of shape (512,)\n",
      "2022-04-02 12:03:53,964 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.6.conv1.weight                                     loaded from backbone.body.layer2.6.conv1.weight                                     of shape (512, 512, 1, 1)\n",
      "2022-04-02 12:03:53,964 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.6.conv2.weight                                     loaded from backbone.body.layer2.6.conv2.weight                                     of shape (512, 16, 3, 3)\n",
      "2022-04-02 12:03:53,965 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.6.conv3.weight                                     loaded from backbone.body.layer2.6.conv3.weight                                     of shape (512, 512, 1, 1)\n",
      "2022-04-02 12:03:53,965 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.7.bn1.bias                                         loaded from backbone.body.layer2.7.bn1.bias                                         of shape (512,)\n",
      "2022-04-02 12:03:53,965 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.7.bn1.running_mean                                 loaded from backbone.body.layer2.7.bn1.running_mean                                 of shape (512,)\n",
      "2022-04-02 12:03:53,965 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.7.bn1.running_var                                  loaded from backbone.body.layer2.7.bn1.running_var                                  of shape (512,)\n",
      "2022-04-02 12:03:53,965 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.7.bn1.weight                                       loaded from backbone.body.layer2.7.bn1.weight                                       of shape (512,)\n",
      "2022-04-02 12:03:53,965 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.7.bn2.bias                                         loaded from backbone.body.layer2.7.bn2.bias                                         of shape (512,)\n",
      "2022-04-02 12:03:53,965 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.7.bn2.running_mean                                 loaded from backbone.body.layer2.7.bn2.running_mean                                 of shape (512,)\n",
      "2022-04-02 12:03:53,965 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.7.bn2.running_var                                  loaded from backbone.body.layer2.7.bn2.running_var                                  of shape (512,)\n",
      "2022-04-02 12:03:53,965 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.7.bn2.weight                                       loaded from backbone.body.layer2.7.bn2.weight                                       of shape (512,)\n",
      "2022-04-02 12:03:53,965 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.7.bn3.bias                                         loaded from backbone.body.layer2.7.bn3.bias                                         of shape (512,)\n",
      "2022-04-02 12:03:53,965 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.7.bn3.running_mean                                 loaded from backbone.body.layer2.7.bn3.running_mean                                 of shape (512,)\n",
      "2022-04-02 12:03:53,965 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.7.bn3.running_var                                  loaded from backbone.body.layer2.7.bn3.running_var                                  of shape (512,)\n",
      "2022-04-02 12:03:53,966 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.7.bn3.weight                                       loaded from backbone.body.layer2.7.bn3.weight                                       of shape (512,)\n",
      "2022-04-02 12:03:53,966 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.7.conv1.weight                                     loaded from backbone.body.layer2.7.conv1.weight                                     of shape (512, 512, 1, 1)\n",
      "2022-04-02 12:03:53,966 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.7.conv2.weight                                     loaded from backbone.body.layer2.7.conv2.weight                                     of shape (512, 16, 3, 3)\n",
      "2022-04-02 12:03:53,966 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.7.conv3.weight                                     loaded from backbone.body.layer2.7.conv3.weight                                     of shape (512, 512, 1, 1)\n",
      "2022-04-02 12:03:53,966 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.bias                                         loaded from backbone.body.layer3.0.bn1.bias                                         of shape (1024,)\n",
      "2022-04-02 12:03:53,966 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.running_mean                                 loaded from backbone.body.layer3.0.bn1.running_mean                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,966 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.running_var                                  loaded from backbone.body.layer3.0.bn1.running_var                                  of shape (1024,)\n",
      "2022-04-02 12:03:53,966 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.weight                                       loaded from backbone.body.layer3.0.bn1.weight                                       of shape (1024,)\n",
      "2022-04-02 12:03:53,966 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.bias                                         loaded from backbone.body.layer3.0.bn2.bias                                         of shape (1024,)\n",
      "2022-04-02 12:03:53,966 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.running_mean                                 loaded from backbone.body.layer3.0.bn2.running_mean                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,966 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.running_var                                  loaded from backbone.body.layer3.0.bn2.running_var                                  of shape (1024,)\n",
      "2022-04-02 12:03:53,966 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.weight                                       loaded from backbone.body.layer3.0.bn2.weight                                       of shape (1024,)\n",
      "2022-04-02 12:03:53,966 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.bias                                         loaded from backbone.body.layer3.0.bn3.bias                                         of shape (1024,)\n",
      "2022-04-02 12:03:53,966 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.running_mean                                 loaded from backbone.body.layer3.0.bn3.running_mean                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,966 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.running_var                                  loaded from backbone.body.layer3.0.bn3.running_var                                  of shape (1024,)\n",
      "2022-04-02 12:03:53,966 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.weight                                       loaded from backbone.body.layer3.0.bn3.weight                                       of shape (1024,)\n",
      "2022-04-02 12:03:53,966 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv1.weight                                     loaded from backbone.body.layer3.0.conv1.weight                                     of shape (1024, 512, 1, 1)\n",
      "2022-04-02 12:03:53,966 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv2.weight                                     loaded from backbone.body.layer3.0.conv2.weight                                     of shape (1024, 32, 3, 3)\n",
      "2022-04-02 12:03:53,966 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv3.weight                                     loaded from backbone.body.layer3.0.conv3.weight                                     of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,966 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.0.weight                              loaded from backbone.body.layer3.0.downsample.0.weight                              of shape (1024, 512, 1, 1)\n",
      "2022-04-02 12:03:53,966 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.bias                                loaded from backbone.body.layer3.0.downsample.1.bias                                of shape (1024,)\n",
      "2022-04-02 12:03:53,966 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.running_mean                        loaded from backbone.body.layer3.0.downsample.1.running_mean                        of shape (1024,)\n",
      "2022-04-02 12:03:53,966 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.running_var                         loaded from backbone.body.layer3.0.downsample.1.running_var                         of shape (1024,)\n",
      "2022-04-02 12:03:53,966 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.weight                              loaded from backbone.body.layer3.0.downsample.1.weight                              of shape (1024,)\n",
      "2022-04-02 12:03:53,967 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.bias                                         loaded from backbone.body.layer3.1.bn1.bias                                         of shape (1024,)\n",
      "2022-04-02 12:03:53,967 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.running_mean                                 loaded from backbone.body.layer3.1.bn1.running_mean                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,967 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.running_var                                  loaded from backbone.body.layer3.1.bn1.running_var                                  of shape (1024,)\n",
      "2022-04-02 12:03:53,967 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.weight                                       loaded from backbone.body.layer3.1.bn1.weight                                       of shape (1024,)\n",
      "2022-04-02 12:03:53,967 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.bias                                         loaded from backbone.body.layer3.1.bn2.bias                                         of shape (1024,)\n",
      "2022-04-02 12:03:53,967 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.running_mean                                 loaded from backbone.body.layer3.1.bn2.running_mean                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,967 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.running_var                                  loaded from backbone.body.layer3.1.bn2.running_var                                  of shape (1024,)\n",
      "2022-04-02 12:03:53,967 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.weight                                       loaded from backbone.body.layer3.1.bn2.weight                                       of shape (1024,)\n",
      "2022-04-02 12:03:53,967 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.bias                                         loaded from backbone.body.layer3.1.bn3.bias                                         of shape (1024,)\n",
      "2022-04-02 12:03:53,967 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.running_mean                                 loaded from backbone.body.layer3.1.bn3.running_mean                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,967 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.running_var                                  loaded from backbone.body.layer3.1.bn3.running_var                                  of shape (1024,)\n",
      "2022-04-02 12:03:53,967 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.weight                                       loaded from backbone.body.layer3.1.bn3.weight                                       of shape (1024,)\n",
      "2022-04-02 12:03:53,967 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv1.weight                                     loaded from backbone.body.layer3.1.conv1.weight                                     of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,967 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv2.weight                                     loaded from backbone.body.layer3.1.conv2.weight                                     of shape (1024, 32, 3, 3)\n",
      "2022-04-02 12:03:53,967 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv3.weight                                     loaded from backbone.body.layer3.1.conv3.weight                                     of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,967 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.bias                                        loaded from backbone.body.layer3.10.bn1.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,967 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.running_mean                                loaded from backbone.body.layer3.10.bn1.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,967 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.running_var                                 loaded from backbone.body.layer3.10.bn1.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,967 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.weight                                      loaded from backbone.body.layer3.10.bn1.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,967 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.bias                                        loaded from backbone.body.layer3.10.bn2.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,967 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.running_mean                                loaded from backbone.body.layer3.10.bn2.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,967 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.running_var                                 loaded from backbone.body.layer3.10.bn2.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,967 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.weight                                      loaded from backbone.body.layer3.10.bn2.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,967 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.bias                                        loaded from backbone.body.layer3.10.bn3.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,967 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.running_mean                                loaded from backbone.body.layer3.10.bn3.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,968 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.running_var                                 loaded from backbone.body.layer3.10.bn3.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,968 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.weight                                      loaded from backbone.body.layer3.10.bn3.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,968 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.conv1.weight                                    loaded from backbone.body.layer3.10.conv1.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,968 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.conv2.weight                                    loaded from backbone.body.layer3.10.conv2.weight                                    of shape (1024, 32, 3, 3)\n",
      "2022-04-02 12:03:53,968 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.conv3.weight                                    loaded from backbone.body.layer3.10.conv3.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,968 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.bias                                        loaded from backbone.body.layer3.11.bn1.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,968 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.running_mean                                loaded from backbone.body.layer3.11.bn1.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,968 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.running_var                                 loaded from backbone.body.layer3.11.bn1.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,968 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.weight                                      loaded from backbone.body.layer3.11.bn1.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,968 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.bias                                        loaded from backbone.body.layer3.11.bn2.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,968 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.running_mean                                loaded from backbone.body.layer3.11.bn2.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,968 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.running_var                                 loaded from backbone.body.layer3.11.bn2.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,968 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.weight                                      loaded from backbone.body.layer3.11.bn2.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,968 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.bias                                        loaded from backbone.body.layer3.11.bn3.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,968 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.running_mean                                loaded from backbone.body.layer3.11.bn3.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,968 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.running_var                                 loaded from backbone.body.layer3.11.bn3.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,968 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.weight                                      loaded from backbone.body.layer3.11.bn3.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,968 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.conv1.weight                                    loaded from backbone.body.layer3.11.conv1.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,968 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.conv2.weight                                    loaded from backbone.body.layer3.11.conv2.weight                                    of shape (1024, 32, 3, 3)\n",
      "2022-04-02 12:03:53,968 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.conv3.weight                                    loaded from backbone.body.layer3.11.conv3.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,968 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.bias                                        loaded from backbone.body.layer3.12.bn1.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,968 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.running_mean                                loaded from backbone.body.layer3.12.bn1.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,968 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.running_var                                 loaded from backbone.body.layer3.12.bn1.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,968 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.weight                                      loaded from backbone.body.layer3.12.bn1.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,968 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.bias                                        loaded from backbone.body.layer3.12.bn2.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,969 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.running_mean                                loaded from backbone.body.layer3.12.bn2.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,969 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.running_var                                 loaded from backbone.body.layer3.12.bn2.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,969 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.weight                                      loaded from backbone.body.layer3.12.bn2.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,969 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.bias                                        loaded from backbone.body.layer3.12.bn3.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,969 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.running_mean                                loaded from backbone.body.layer3.12.bn3.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,969 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.running_var                                 loaded from backbone.body.layer3.12.bn3.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,969 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.weight                                      loaded from backbone.body.layer3.12.bn3.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,969 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.conv1.weight                                    loaded from backbone.body.layer3.12.conv1.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,969 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.conv2.weight                                    loaded from backbone.body.layer3.12.conv2.weight                                    of shape (1024, 32, 3, 3)\n",
      "2022-04-02 12:03:53,969 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.conv3.weight                                    loaded from backbone.body.layer3.12.conv3.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,969 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.bias                                        loaded from backbone.body.layer3.13.bn1.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,969 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.running_mean                                loaded from backbone.body.layer3.13.bn1.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,969 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.running_var                                 loaded from backbone.body.layer3.13.bn1.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,969 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.weight                                      loaded from backbone.body.layer3.13.bn1.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,969 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.bias                                        loaded from backbone.body.layer3.13.bn2.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,969 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.running_mean                                loaded from backbone.body.layer3.13.bn2.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,969 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.running_var                                 loaded from backbone.body.layer3.13.bn2.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,969 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.weight                                      loaded from backbone.body.layer3.13.bn2.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,969 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.bias                                        loaded from backbone.body.layer3.13.bn3.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,969 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.running_mean                                loaded from backbone.body.layer3.13.bn3.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,969 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.running_var                                 loaded from backbone.body.layer3.13.bn3.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,969 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.weight                                      loaded from backbone.body.layer3.13.bn3.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,969 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.conv1.weight                                    loaded from backbone.body.layer3.13.conv1.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,969 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.conv2.weight                                    loaded from backbone.body.layer3.13.conv2.weight                                    of shape (1024, 32, 3, 3)\n",
      "2022-04-02 12:03:53,969 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.conv3.weight                                    loaded from backbone.body.layer3.13.conv3.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,970 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.bias                                        loaded from backbone.body.layer3.14.bn1.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,970 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.running_mean                                loaded from backbone.body.layer3.14.bn1.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,970 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.running_var                                 loaded from backbone.body.layer3.14.bn1.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,970 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.weight                                      loaded from backbone.body.layer3.14.bn1.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,970 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.bias                                        loaded from backbone.body.layer3.14.bn2.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,970 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.running_mean                                loaded from backbone.body.layer3.14.bn2.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,970 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.running_var                                 loaded from backbone.body.layer3.14.bn2.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,970 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.weight                                      loaded from backbone.body.layer3.14.bn2.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,970 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.bias                                        loaded from backbone.body.layer3.14.bn3.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,970 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.running_mean                                loaded from backbone.body.layer3.14.bn3.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,970 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.running_var                                 loaded from backbone.body.layer3.14.bn3.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,970 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.weight                                      loaded from backbone.body.layer3.14.bn3.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,970 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.conv1.weight                                    loaded from backbone.body.layer3.14.conv1.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,970 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.conv2.weight                                    loaded from backbone.body.layer3.14.conv2.weight                                    of shape (1024, 32, 3, 3)\n",
      "2022-04-02 12:03:53,970 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.conv3.weight                                    loaded from backbone.body.layer3.14.conv3.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,970 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.bias                                        loaded from backbone.body.layer3.15.bn1.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,970 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.running_mean                                loaded from backbone.body.layer3.15.bn1.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,970 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.running_var                                 loaded from backbone.body.layer3.15.bn1.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,970 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.weight                                      loaded from backbone.body.layer3.15.bn1.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,970 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.bias                                        loaded from backbone.body.layer3.15.bn2.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,970 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.running_mean                                loaded from backbone.body.layer3.15.bn2.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,970 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.running_var                                 loaded from backbone.body.layer3.15.bn2.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,970 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.weight                                      loaded from backbone.body.layer3.15.bn2.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,970 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.bias                                        loaded from backbone.body.layer3.15.bn3.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,971 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.running_mean                                loaded from backbone.body.layer3.15.bn3.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,972 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.running_var                                 loaded from backbone.body.layer3.15.bn3.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,972 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.weight                                      loaded from backbone.body.layer3.15.bn3.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,972 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.conv1.weight                                    loaded from backbone.body.layer3.15.conv1.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,972 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.conv2.weight                                    loaded from backbone.body.layer3.15.conv2.weight                                    of shape (1024, 32, 3, 3)\n",
      "2022-04-02 12:03:53,972 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.conv3.weight                                    loaded from backbone.body.layer3.15.conv3.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,972 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.bias                                        loaded from backbone.body.layer3.16.bn1.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,972 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.running_mean                                loaded from backbone.body.layer3.16.bn1.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,972 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.running_var                                 loaded from backbone.body.layer3.16.bn1.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,972 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.weight                                      loaded from backbone.body.layer3.16.bn1.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,972 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.bias                                        loaded from backbone.body.layer3.16.bn2.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,972 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.running_mean                                loaded from backbone.body.layer3.16.bn2.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,972 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.running_var                                 loaded from backbone.body.layer3.16.bn2.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,972 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.weight                                      loaded from backbone.body.layer3.16.bn2.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,972 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.bias                                        loaded from backbone.body.layer3.16.bn3.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,972 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.running_mean                                loaded from backbone.body.layer3.16.bn3.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,972 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.running_var                                 loaded from backbone.body.layer3.16.bn3.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,973 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.weight                                      loaded from backbone.body.layer3.16.bn3.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,973 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.conv1.weight                                    loaded from backbone.body.layer3.16.conv1.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,973 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.conv2.weight                                    loaded from backbone.body.layer3.16.conv2.weight                                    of shape (1024, 32, 3, 3)\n",
      "2022-04-02 12:03:53,973 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.conv3.weight                                    loaded from backbone.body.layer3.16.conv3.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,973 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.bias                                        loaded from backbone.body.layer3.17.bn1.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,973 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.running_mean                                loaded from backbone.body.layer3.17.bn1.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,973 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.running_var                                 loaded from backbone.body.layer3.17.bn1.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,973 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.weight                                      loaded from backbone.body.layer3.17.bn1.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,973 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.bias                                        loaded from backbone.body.layer3.17.bn2.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,973 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.running_mean                                loaded from backbone.body.layer3.17.bn2.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,973 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.running_var                                 loaded from backbone.body.layer3.17.bn2.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,973 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.weight                                      loaded from backbone.body.layer3.17.bn2.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,973 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.bias                                        loaded from backbone.body.layer3.17.bn3.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,973 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.running_mean                                loaded from backbone.body.layer3.17.bn3.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,973 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.running_var                                 loaded from backbone.body.layer3.17.bn3.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,973 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.weight                                      loaded from backbone.body.layer3.17.bn3.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,973 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.conv1.weight                                    loaded from backbone.body.layer3.17.conv1.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,973 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.conv2.weight                                    loaded from backbone.body.layer3.17.conv2.weight                                    of shape (1024, 32, 3, 3)\n",
      "2022-04-02 12:03:53,973 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.conv3.weight                                    loaded from backbone.body.layer3.17.conv3.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,973 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.bias                                        loaded from backbone.body.layer3.18.bn1.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,973 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.running_mean                                loaded from backbone.body.layer3.18.bn1.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,974 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.running_var                                 loaded from backbone.body.layer3.18.bn1.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,974 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.weight                                      loaded from backbone.body.layer3.18.bn1.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,974 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.bias                                        loaded from backbone.body.layer3.18.bn2.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,974 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.running_mean                                loaded from backbone.body.layer3.18.bn2.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,974 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.running_var                                 loaded from backbone.body.layer3.18.bn2.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,974 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.weight                                      loaded from backbone.body.layer3.18.bn2.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,974 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.bias                                        loaded from backbone.body.layer3.18.bn3.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,974 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.running_mean                                loaded from backbone.body.layer3.18.bn3.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,974 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.running_var                                 loaded from backbone.body.layer3.18.bn3.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,974 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.weight                                      loaded from backbone.body.layer3.18.bn3.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,974 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.conv1.weight                                    loaded from backbone.body.layer3.18.conv1.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,974 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.conv2.weight                                    loaded from backbone.body.layer3.18.conv2.weight                                    of shape (1024, 32, 3, 3)\n",
      "2022-04-02 12:03:53,974 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.conv3.weight                                    loaded from backbone.body.layer3.18.conv3.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,974 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.bias                                        loaded from backbone.body.layer3.19.bn1.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,974 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.running_mean                                loaded from backbone.body.layer3.19.bn1.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,974 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.running_var                                 loaded from backbone.body.layer3.19.bn1.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,974 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.weight                                      loaded from backbone.body.layer3.19.bn1.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,974 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.bias                                        loaded from backbone.body.layer3.19.bn2.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,974 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.running_mean                                loaded from backbone.body.layer3.19.bn2.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,974 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.running_var                                 loaded from backbone.body.layer3.19.bn2.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.weight                                      loaded from backbone.body.layer3.19.bn2.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.bias                                        loaded from backbone.body.layer3.19.bn3.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.running_mean                                loaded from backbone.body.layer3.19.bn3.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.running_var                                 loaded from backbone.body.layer3.19.bn3.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.weight                                      loaded from backbone.body.layer3.19.bn3.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.conv1.weight                                    loaded from backbone.body.layer3.19.conv1.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.conv2.weight                                    loaded from backbone.body.layer3.19.conv2.weight                                    of shape (1024, 32, 3, 3)\n",
      "2022-04-02 12:03:53,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.conv3.weight                                    loaded from backbone.body.layer3.19.conv3.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.bias                                         loaded from backbone.body.layer3.2.bn1.bias                                         of shape (1024,)\n",
      "2022-04-02 12:03:53,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.running_mean                                 loaded from backbone.body.layer3.2.bn1.running_mean                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.running_var                                  loaded from backbone.body.layer3.2.bn1.running_var                                  of shape (1024,)\n",
      "2022-04-02 12:03:53,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.weight                                       loaded from backbone.body.layer3.2.bn1.weight                                       of shape (1024,)\n",
      "2022-04-02 12:03:53,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.bias                                         loaded from backbone.body.layer3.2.bn2.bias                                         of shape (1024,)\n",
      "2022-04-02 12:03:53,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.running_mean                                 loaded from backbone.body.layer3.2.bn2.running_mean                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.running_var                                  loaded from backbone.body.layer3.2.bn2.running_var                                  of shape (1024,)\n",
      "2022-04-02 12:03:53,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.weight                                       loaded from backbone.body.layer3.2.bn2.weight                                       of shape (1024,)\n",
      "2022-04-02 12:03:53,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.bias                                         loaded from backbone.body.layer3.2.bn3.bias                                         of shape (1024,)\n",
      "2022-04-02 12:03:53,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.running_mean                                 loaded from backbone.body.layer3.2.bn3.running_mean                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.running_var                                  loaded from backbone.body.layer3.2.bn3.running_var                                  of shape (1024,)\n",
      "2022-04-02 12:03:53,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.weight                                       loaded from backbone.body.layer3.2.bn3.weight                                       of shape (1024,)\n",
      "2022-04-02 12:03:53,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv1.weight                                     loaded from backbone.body.layer3.2.conv1.weight                                     of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv2.weight                                     loaded from backbone.body.layer3.2.conv2.weight                                     of shape (1024, 32, 3, 3)\n",
      "2022-04-02 12:03:53,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv3.weight                                     loaded from backbone.body.layer3.2.conv3.weight                                     of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.bias                                        loaded from backbone.body.layer3.20.bn1.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.running_mean                                loaded from backbone.body.layer3.20.bn1.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.running_var                                 loaded from backbone.body.layer3.20.bn1.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.weight                                      loaded from backbone.body.layer3.20.bn1.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.bias                                        loaded from backbone.body.layer3.20.bn2.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.running_mean                                loaded from backbone.body.layer3.20.bn2.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.running_var                                 loaded from backbone.body.layer3.20.bn2.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.weight                                      loaded from backbone.body.layer3.20.bn2.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.bias                                        loaded from backbone.body.layer3.20.bn3.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.running_mean                                loaded from backbone.body.layer3.20.bn3.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.running_var                                 loaded from backbone.body.layer3.20.bn3.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.weight                                      loaded from backbone.body.layer3.20.bn3.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.conv1.weight                                    loaded from backbone.body.layer3.20.conv1.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.conv2.weight                                    loaded from backbone.body.layer3.20.conv2.weight                                    of shape (1024, 32, 3, 3)\n",
      "2022-04-02 12:03:53,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.conv3.weight                                    loaded from backbone.body.layer3.20.conv3.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.bias                                        loaded from backbone.body.layer3.21.bn1.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.running_mean                                loaded from backbone.body.layer3.21.bn1.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.running_var                                 loaded from backbone.body.layer3.21.bn1.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.weight                                      loaded from backbone.body.layer3.21.bn1.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.bias                                        loaded from backbone.body.layer3.21.bn2.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.running_mean                                loaded from backbone.body.layer3.21.bn2.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.running_var                                 loaded from backbone.body.layer3.21.bn2.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.weight                                      loaded from backbone.body.layer3.21.bn2.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.bias                                        loaded from backbone.body.layer3.21.bn3.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.running_mean                                loaded from backbone.body.layer3.21.bn3.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.running_var                                 loaded from backbone.body.layer3.21.bn3.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.weight                                      loaded from backbone.body.layer3.21.bn3.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.conv1.weight                                    loaded from backbone.body.layer3.21.conv1.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.conv2.weight                                    loaded from backbone.body.layer3.21.conv2.weight                                    of shape (1024, 32, 3, 3)\n",
      "2022-04-02 12:03:53,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.conv3.weight                                    loaded from backbone.body.layer3.21.conv3.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.bias                                        loaded from backbone.body.layer3.22.bn1.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.running_mean                                loaded from backbone.body.layer3.22.bn1.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.running_var                                 loaded from backbone.body.layer3.22.bn1.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.weight                                      loaded from backbone.body.layer3.22.bn1.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.bias                                        loaded from backbone.body.layer3.22.bn2.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.running_mean                                loaded from backbone.body.layer3.22.bn2.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.running_var                                 loaded from backbone.body.layer3.22.bn2.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.weight                                      loaded from backbone.body.layer3.22.bn2.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.bias                                        loaded from backbone.body.layer3.22.bn3.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.running_mean                                loaded from backbone.body.layer3.22.bn3.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.running_var                                 loaded from backbone.body.layer3.22.bn3.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.weight                                      loaded from backbone.body.layer3.22.bn3.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.conv1.weight                                    loaded from backbone.body.layer3.22.conv1.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.conv2.weight                                    loaded from backbone.body.layer3.22.conv2.weight                                    of shape (1024, 32, 3, 3)\n",
      "2022-04-02 12:03:53,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.conv3.weight                                    loaded from backbone.body.layer3.22.conv3.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.23.bn1.bias                                        loaded from backbone.body.layer3.23.bn1.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.23.bn1.running_mean                                loaded from backbone.body.layer3.23.bn1.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.23.bn1.running_var                                 loaded from backbone.body.layer3.23.bn1.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.23.bn1.weight                                      loaded from backbone.body.layer3.23.bn1.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.23.bn2.bias                                        loaded from backbone.body.layer3.23.bn2.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.23.bn2.running_mean                                loaded from backbone.body.layer3.23.bn2.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.23.bn2.running_var                                 loaded from backbone.body.layer3.23.bn2.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.23.bn2.weight                                      loaded from backbone.body.layer3.23.bn2.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.23.bn3.bias                                        loaded from backbone.body.layer3.23.bn3.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.23.bn3.running_mean                                loaded from backbone.body.layer3.23.bn3.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.23.bn3.running_var                                 loaded from backbone.body.layer3.23.bn3.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.23.bn3.weight                                      loaded from backbone.body.layer3.23.bn3.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.23.conv1.weight                                    loaded from backbone.body.layer3.23.conv1.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.23.conv2.weight                                    loaded from backbone.body.layer3.23.conv2.weight                                    of shape (1024, 32, 3, 3)\n",
      "2022-04-02 12:03:53,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.23.conv3.weight                                    loaded from backbone.body.layer3.23.conv3.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.24.bn1.bias                                        loaded from backbone.body.layer3.24.bn1.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.24.bn1.running_mean                                loaded from backbone.body.layer3.24.bn1.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.24.bn1.running_var                                 loaded from backbone.body.layer3.24.bn1.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.24.bn1.weight                                      loaded from backbone.body.layer3.24.bn1.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.24.bn2.bias                                        loaded from backbone.body.layer3.24.bn2.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.24.bn2.running_mean                                loaded from backbone.body.layer3.24.bn2.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.24.bn2.running_var                                 loaded from backbone.body.layer3.24.bn2.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.24.bn2.weight                                      loaded from backbone.body.layer3.24.bn2.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.24.bn3.bias                                        loaded from backbone.body.layer3.24.bn3.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.24.bn3.running_mean                                loaded from backbone.body.layer3.24.bn3.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.24.bn3.running_var                                 loaded from backbone.body.layer3.24.bn3.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.24.bn3.weight                                      loaded from backbone.body.layer3.24.bn3.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.24.conv1.weight                                    loaded from backbone.body.layer3.24.conv1.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.24.conv2.weight                                    loaded from backbone.body.layer3.24.conv2.weight                                    of shape (1024, 32, 3, 3)\n",
      "2022-04-02 12:03:53,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.24.conv3.weight                                    loaded from backbone.body.layer3.24.conv3.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.25.bn1.bias                                        loaded from backbone.body.layer3.25.bn1.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.25.bn1.running_mean                                loaded from backbone.body.layer3.25.bn1.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.25.bn1.running_var                                 loaded from backbone.body.layer3.25.bn1.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.25.bn1.weight                                      loaded from backbone.body.layer3.25.bn1.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.25.bn2.bias                                        loaded from backbone.body.layer3.25.bn2.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.25.bn2.running_mean                                loaded from backbone.body.layer3.25.bn2.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.25.bn2.running_var                                 loaded from backbone.body.layer3.25.bn2.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.25.bn2.weight                                      loaded from backbone.body.layer3.25.bn2.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.25.bn3.bias                                        loaded from backbone.body.layer3.25.bn3.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.25.bn3.running_mean                                loaded from backbone.body.layer3.25.bn3.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.25.bn3.running_var                                 loaded from backbone.body.layer3.25.bn3.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.25.bn3.weight                                      loaded from backbone.body.layer3.25.bn3.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.25.conv1.weight                                    loaded from backbone.body.layer3.25.conv1.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.25.conv2.weight                                    loaded from backbone.body.layer3.25.conv2.weight                                    of shape (1024, 32, 3, 3)\n",
      "2022-04-02 12:03:53,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.25.conv3.weight                                    loaded from backbone.body.layer3.25.conv3.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.26.bn1.bias                                        loaded from backbone.body.layer3.26.bn1.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.26.bn1.running_mean                                loaded from backbone.body.layer3.26.bn1.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.26.bn1.running_var                                 loaded from backbone.body.layer3.26.bn1.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.26.bn1.weight                                      loaded from backbone.body.layer3.26.bn1.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.26.bn2.bias                                        loaded from backbone.body.layer3.26.bn2.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.26.bn2.running_mean                                loaded from backbone.body.layer3.26.bn2.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.26.bn2.running_var                                 loaded from backbone.body.layer3.26.bn2.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.26.bn2.weight                                      loaded from backbone.body.layer3.26.bn2.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.26.bn3.bias                                        loaded from backbone.body.layer3.26.bn3.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.26.bn3.running_mean                                loaded from backbone.body.layer3.26.bn3.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.26.bn3.running_var                                 loaded from backbone.body.layer3.26.bn3.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.26.bn3.weight                                      loaded from backbone.body.layer3.26.bn3.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.26.conv1.weight                                    loaded from backbone.body.layer3.26.conv1.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.26.conv2.weight                                    loaded from backbone.body.layer3.26.conv2.weight                                    of shape (1024, 32, 3, 3)\n",
      "2022-04-02 12:03:53,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.26.conv3.weight                                    loaded from backbone.body.layer3.26.conv3.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.27.bn1.bias                                        loaded from backbone.body.layer3.27.bn1.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.27.bn1.running_mean                                loaded from backbone.body.layer3.27.bn1.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.27.bn1.running_var                                 loaded from backbone.body.layer3.27.bn1.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.27.bn1.weight                                      loaded from backbone.body.layer3.27.bn1.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.27.bn2.bias                                        loaded from backbone.body.layer3.27.bn2.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.27.bn2.running_mean                                loaded from backbone.body.layer3.27.bn2.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.27.bn2.running_var                                 loaded from backbone.body.layer3.27.bn2.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.27.bn2.weight                                      loaded from backbone.body.layer3.27.bn2.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.27.bn3.bias                                        loaded from backbone.body.layer3.27.bn3.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.27.bn3.running_mean                                loaded from backbone.body.layer3.27.bn3.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.27.bn3.running_var                                 loaded from backbone.body.layer3.27.bn3.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.27.bn3.weight                                      loaded from backbone.body.layer3.27.bn3.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.27.conv1.weight                                    loaded from backbone.body.layer3.27.conv1.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.27.conv2.weight                                    loaded from backbone.body.layer3.27.conv2.weight                                    of shape (1024, 32, 3, 3)\n",
      "2022-04-02 12:03:53,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.27.conv3.weight                                    loaded from backbone.body.layer3.27.conv3.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.28.bn1.bias                                        loaded from backbone.body.layer3.28.bn1.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.28.bn1.running_mean                                loaded from backbone.body.layer3.28.bn1.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.28.bn1.running_var                                 loaded from backbone.body.layer3.28.bn1.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.28.bn1.weight                                      loaded from backbone.body.layer3.28.bn1.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.28.bn2.bias                                        loaded from backbone.body.layer3.28.bn2.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.28.bn2.running_mean                                loaded from backbone.body.layer3.28.bn2.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.28.bn2.running_var                                 loaded from backbone.body.layer3.28.bn2.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.28.bn2.weight                                      loaded from backbone.body.layer3.28.bn2.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.28.bn3.bias                                        loaded from backbone.body.layer3.28.bn3.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.28.bn3.running_mean                                loaded from backbone.body.layer3.28.bn3.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.28.bn3.running_var                                 loaded from backbone.body.layer3.28.bn3.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.28.bn3.weight                                      loaded from backbone.body.layer3.28.bn3.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.28.conv1.weight                                    loaded from backbone.body.layer3.28.conv1.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.28.conv2.weight                                    loaded from backbone.body.layer3.28.conv2.weight                                    of shape (1024, 32, 3, 3)\n",
      "2022-04-02 12:03:53,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.28.conv3.weight                                    loaded from backbone.body.layer3.28.conv3.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.29.bn1.bias                                        loaded from backbone.body.layer3.29.bn1.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.29.bn1.running_mean                                loaded from backbone.body.layer3.29.bn1.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.29.bn1.running_var                                 loaded from backbone.body.layer3.29.bn1.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.29.bn1.weight                                      loaded from backbone.body.layer3.29.bn1.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.29.bn2.bias                                        loaded from backbone.body.layer3.29.bn2.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.29.bn2.running_mean                                loaded from backbone.body.layer3.29.bn2.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.29.bn2.running_var                                 loaded from backbone.body.layer3.29.bn2.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.29.bn2.weight                                      loaded from backbone.body.layer3.29.bn2.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.29.bn3.bias                                        loaded from backbone.body.layer3.29.bn3.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.29.bn3.running_mean                                loaded from backbone.body.layer3.29.bn3.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.29.bn3.running_var                                 loaded from backbone.body.layer3.29.bn3.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.29.bn3.weight                                      loaded from backbone.body.layer3.29.bn3.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.29.conv1.weight                                    loaded from backbone.body.layer3.29.conv1.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.29.conv2.weight                                    loaded from backbone.body.layer3.29.conv2.weight                                    of shape (1024, 32, 3, 3)\n",
      "2022-04-02 12:03:53,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.29.conv3.weight                                    loaded from backbone.body.layer3.29.conv3.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.bias                                         loaded from backbone.body.layer3.3.bn1.bias                                         of shape (1024,)\n",
      "2022-04-02 12:03:53,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.running_mean                                 loaded from backbone.body.layer3.3.bn1.running_mean                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.running_var                                  loaded from backbone.body.layer3.3.bn1.running_var                                  of shape (1024,)\n",
      "2022-04-02 12:03:53,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.weight                                       loaded from backbone.body.layer3.3.bn1.weight                                       of shape (1024,)\n",
      "2022-04-02 12:03:53,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.bias                                         loaded from backbone.body.layer3.3.bn2.bias                                         of shape (1024,)\n",
      "2022-04-02 12:03:53,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.running_mean                                 loaded from backbone.body.layer3.3.bn2.running_mean                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.running_var                                  loaded from backbone.body.layer3.3.bn2.running_var                                  of shape (1024,)\n",
      "2022-04-02 12:03:53,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.weight                                       loaded from backbone.body.layer3.3.bn2.weight                                       of shape (1024,)\n",
      "2022-04-02 12:03:53,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.bias                                         loaded from backbone.body.layer3.3.bn3.bias                                         of shape (1024,)\n",
      "2022-04-02 12:03:53,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.running_mean                                 loaded from backbone.body.layer3.3.bn3.running_mean                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.running_var                                  loaded from backbone.body.layer3.3.bn3.running_var                                  of shape (1024,)\n",
      "2022-04-02 12:03:53,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.weight                                       loaded from backbone.body.layer3.3.bn3.weight                                       of shape (1024,)\n",
      "2022-04-02 12:03:53,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv1.weight                                     loaded from backbone.body.layer3.3.conv1.weight                                     of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv2.weight                                     loaded from backbone.body.layer3.3.conv2.weight                                     of shape (1024, 32, 3, 3)\n",
      "2022-04-02 12:03:53,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv3.weight                                     loaded from backbone.body.layer3.3.conv3.weight                                     of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.30.bn1.bias                                        loaded from backbone.body.layer3.30.bn1.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.30.bn1.running_mean                                loaded from backbone.body.layer3.30.bn1.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.30.bn1.running_var                                 loaded from backbone.body.layer3.30.bn1.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.30.bn1.weight                                      loaded from backbone.body.layer3.30.bn1.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.30.bn2.bias                                        loaded from backbone.body.layer3.30.bn2.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.30.bn2.running_mean                                loaded from backbone.body.layer3.30.bn2.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.30.bn2.running_var                                 loaded from backbone.body.layer3.30.bn2.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.30.bn2.weight                                      loaded from backbone.body.layer3.30.bn2.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.30.bn3.bias                                        loaded from backbone.body.layer3.30.bn3.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.30.bn3.running_mean                                loaded from backbone.body.layer3.30.bn3.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.30.bn3.running_var                                 loaded from backbone.body.layer3.30.bn3.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.30.bn3.weight                                      loaded from backbone.body.layer3.30.bn3.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.30.conv1.weight                                    loaded from backbone.body.layer3.30.conv1.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.30.conv2.weight                                    loaded from backbone.body.layer3.30.conv2.weight                                    of shape (1024, 32, 3, 3)\n",
      "2022-04-02 12:03:53,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.30.conv3.weight                                    loaded from backbone.body.layer3.30.conv3.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.31.bn1.bias                                        loaded from backbone.body.layer3.31.bn1.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.31.bn1.running_mean                                loaded from backbone.body.layer3.31.bn1.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.31.bn1.running_var                                 loaded from backbone.body.layer3.31.bn1.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.31.bn1.weight                                      loaded from backbone.body.layer3.31.bn1.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.31.bn2.bias                                        loaded from backbone.body.layer3.31.bn2.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.31.bn2.running_mean                                loaded from backbone.body.layer3.31.bn2.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.31.bn2.running_var                                 loaded from backbone.body.layer3.31.bn2.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.31.bn2.weight                                      loaded from backbone.body.layer3.31.bn2.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.31.bn3.bias                                        loaded from backbone.body.layer3.31.bn3.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.31.bn3.running_mean                                loaded from backbone.body.layer3.31.bn3.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.31.bn3.running_var                                 loaded from backbone.body.layer3.31.bn3.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.31.bn3.weight                                      loaded from backbone.body.layer3.31.bn3.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.31.conv1.weight                                    loaded from backbone.body.layer3.31.conv1.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.31.conv2.weight                                    loaded from backbone.body.layer3.31.conv2.weight                                    of shape (1024, 32, 3, 3)\n",
      "2022-04-02 12:03:53,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.31.conv3.weight                                    loaded from backbone.body.layer3.31.conv3.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.32.bn1.bias                                        loaded from backbone.body.layer3.32.bn1.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.32.bn1.running_mean                                loaded from backbone.body.layer3.32.bn1.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.32.bn1.running_var                                 loaded from backbone.body.layer3.32.bn1.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.32.bn1.weight                                      loaded from backbone.body.layer3.32.bn1.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.32.bn2.bias                                        loaded from backbone.body.layer3.32.bn2.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.32.bn2.running_mean                                loaded from backbone.body.layer3.32.bn2.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.32.bn2.running_var                                 loaded from backbone.body.layer3.32.bn2.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.32.bn2.weight                                      loaded from backbone.body.layer3.32.bn2.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.32.bn3.bias                                        loaded from backbone.body.layer3.32.bn3.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.32.bn3.running_mean                                loaded from backbone.body.layer3.32.bn3.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.32.bn3.running_var                                 loaded from backbone.body.layer3.32.bn3.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.32.bn3.weight                                      loaded from backbone.body.layer3.32.bn3.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.32.conv1.weight                                    loaded from backbone.body.layer3.32.conv1.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.32.conv2.weight                                    loaded from backbone.body.layer3.32.conv2.weight                                    of shape (1024, 32, 3, 3)\n",
      "2022-04-02 12:03:53,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.32.conv3.weight                                    loaded from backbone.body.layer3.32.conv3.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.33.bn1.bias                                        loaded from backbone.body.layer3.33.bn1.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.33.bn1.running_mean                                loaded from backbone.body.layer3.33.bn1.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.33.bn1.running_var                                 loaded from backbone.body.layer3.33.bn1.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.33.bn1.weight                                      loaded from backbone.body.layer3.33.bn1.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.33.bn2.bias                                        loaded from backbone.body.layer3.33.bn2.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.33.bn2.running_mean                                loaded from backbone.body.layer3.33.bn2.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.33.bn2.running_var                                 loaded from backbone.body.layer3.33.bn2.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.33.bn2.weight                                      loaded from backbone.body.layer3.33.bn2.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.33.bn3.bias                                        loaded from backbone.body.layer3.33.bn3.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.33.bn3.running_mean                                loaded from backbone.body.layer3.33.bn3.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.33.bn3.running_var                                 loaded from backbone.body.layer3.33.bn3.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.33.bn3.weight                                      loaded from backbone.body.layer3.33.bn3.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.33.conv1.weight                                    loaded from backbone.body.layer3.33.conv1.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.33.conv2.weight                                    loaded from backbone.body.layer3.33.conv2.weight                                    of shape (1024, 32, 3, 3)\n",
      "2022-04-02 12:03:53,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.33.conv3.weight                                    loaded from backbone.body.layer3.33.conv3.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.34.bn1.bias                                        loaded from backbone.body.layer3.34.bn1.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.34.bn1.running_mean                                loaded from backbone.body.layer3.34.bn1.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.34.bn1.running_var                                 loaded from backbone.body.layer3.34.bn1.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.34.bn1.weight                                      loaded from backbone.body.layer3.34.bn1.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.34.bn2.bias                                        loaded from backbone.body.layer3.34.bn2.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.34.bn2.running_mean                                loaded from backbone.body.layer3.34.bn2.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.34.bn2.running_var                                 loaded from backbone.body.layer3.34.bn2.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.34.bn2.weight                                      loaded from backbone.body.layer3.34.bn2.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.34.bn3.bias                                        loaded from backbone.body.layer3.34.bn3.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.34.bn3.running_mean                                loaded from backbone.body.layer3.34.bn3.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.34.bn3.running_var                                 loaded from backbone.body.layer3.34.bn3.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.34.bn3.weight                                      loaded from backbone.body.layer3.34.bn3.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.34.conv1.weight                                    loaded from backbone.body.layer3.34.conv1.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.34.conv2.weight                                    loaded from backbone.body.layer3.34.conv2.weight                                    of shape (1024, 32, 3, 3)\n",
      "2022-04-02 12:03:53,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.34.conv3.weight                                    loaded from backbone.body.layer3.34.conv3.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.35.bn1.bias                                        loaded from backbone.body.layer3.35.bn1.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.35.bn1.running_mean                                loaded from backbone.body.layer3.35.bn1.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.35.bn1.running_var                                 loaded from backbone.body.layer3.35.bn1.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.35.bn1.weight                                      loaded from backbone.body.layer3.35.bn1.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.35.bn2.bias                                        loaded from backbone.body.layer3.35.bn2.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.35.bn2.running_mean                                loaded from backbone.body.layer3.35.bn2.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.35.bn2.running_var                                 loaded from backbone.body.layer3.35.bn2.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.35.bn2.weight                                      loaded from backbone.body.layer3.35.bn2.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.35.bn3.bias                                        loaded from backbone.body.layer3.35.bn3.bias                                        of shape (1024,)\n",
      "2022-04-02 12:03:53,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.35.bn3.running_mean                                loaded from backbone.body.layer3.35.bn3.running_mean                                of shape (1024,)\n",
      "2022-04-02 12:03:53,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.35.bn3.running_var                                 loaded from backbone.body.layer3.35.bn3.running_var                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.35.bn3.weight                                      loaded from backbone.body.layer3.35.bn3.weight                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.35.conv1.weight                                    loaded from backbone.body.layer3.35.conv1.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.35.conv2.weight                                    loaded from backbone.body.layer3.35.conv2.weight                                    of shape (1024, 32, 3, 3)\n",
      "2022-04-02 12:03:53,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.35.conv3.weight                                    loaded from backbone.body.layer3.35.conv3.weight                                    of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.bias                                         loaded from backbone.body.layer3.4.bn1.bias                                         of shape (1024,)\n",
      "2022-04-02 12:03:53,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.running_mean                                 loaded from backbone.body.layer3.4.bn1.running_mean                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.running_var                                  loaded from backbone.body.layer3.4.bn1.running_var                                  of shape (1024,)\n",
      "2022-04-02 12:03:53,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.weight                                       loaded from backbone.body.layer3.4.bn1.weight                                       of shape (1024,)\n",
      "2022-04-02 12:03:53,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.bias                                         loaded from backbone.body.layer3.4.bn2.bias                                         of shape (1024,)\n",
      "2022-04-02 12:03:53,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.running_mean                                 loaded from backbone.body.layer3.4.bn2.running_mean                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.running_var                                  loaded from backbone.body.layer3.4.bn2.running_var                                  of shape (1024,)\n",
      "2022-04-02 12:03:53,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.weight                                       loaded from backbone.body.layer3.4.bn2.weight                                       of shape (1024,)\n",
      "2022-04-02 12:03:53,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.bias                                         loaded from backbone.body.layer3.4.bn3.bias                                         of shape (1024,)\n",
      "2022-04-02 12:03:53,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.running_mean                                 loaded from backbone.body.layer3.4.bn3.running_mean                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.running_var                                  loaded from backbone.body.layer3.4.bn3.running_var                                  of shape (1024,)\n",
      "2022-04-02 12:03:53,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.weight                                       loaded from backbone.body.layer3.4.bn3.weight                                       of shape (1024,)\n",
      "2022-04-02 12:03:53,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv1.weight                                     loaded from backbone.body.layer3.4.conv1.weight                                     of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv2.weight                                     loaded from backbone.body.layer3.4.conv2.weight                                     of shape (1024, 32, 3, 3)\n",
      "2022-04-02 12:03:53,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv3.weight                                     loaded from backbone.body.layer3.4.conv3.weight                                     of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.bias                                         loaded from backbone.body.layer3.5.bn1.bias                                         of shape (1024,)\n",
      "2022-04-02 12:03:53,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.running_mean                                 loaded from backbone.body.layer3.5.bn1.running_mean                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.running_var                                  loaded from backbone.body.layer3.5.bn1.running_var                                  of shape (1024,)\n",
      "2022-04-02 12:03:53,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.weight                                       loaded from backbone.body.layer3.5.bn1.weight                                       of shape (1024,)\n",
      "2022-04-02 12:03:53,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.bias                                         loaded from backbone.body.layer3.5.bn2.bias                                         of shape (1024,)\n",
      "2022-04-02 12:03:53,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.running_mean                                 loaded from backbone.body.layer3.5.bn2.running_mean                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.running_var                                  loaded from backbone.body.layer3.5.bn2.running_var                                  of shape (1024,)\n",
      "2022-04-02 12:03:53,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.weight                                       loaded from backbone.body.layer3.5.bn2.weight                                       of shape (1024,)\n",
      "2022-04-02 12:03:53,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.bias                                         loaded from backbone.body.layer3.5.bn3.bias                                         of shape (1024,)\n",
      "2022-04-02 12:03:53,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.running_mean                                 loaded from backbone.body.layer3.5.bn3.running_mean                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.running_var                                  loaded from backbone.body.layer3.5.bn3.running_var                                  of shape (1024,)\n",
      "2022-04-02 12:03:53,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.weight                                       loaded from backbone.body.layer3.5.bn3.weight                                       of shape (1024,)\n",
      "2022-04-02 12:03:53,986 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv1.weight                                     loaded from backbone.body.layer3.5.conv1.weight                                     of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,986 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv2.weight                                     loaded from backbone.body.layer3.5.conv2.weight                                     of shape (1024, 32, 3, 3)\n",
      "2022-04-02 12:03:53,986 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv3.weight                                     loaded from backbone.body.layer3.5.conv3.weight                                     of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,986 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.bias                                         loaded from backbone.body.layer3.6.bn1.bias                                         of shape (1024,)\n",
      "2022-04-02 12:03:53,986 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.running_mean                                 loaded from backbone.body.layer3.6.bn1.running_mean                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,986 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.running_var                                  loaded from backbone.body.layer3.6.bn1.running_var                                  of shape (1024,)\n",
      "2022-04-02 12:03:53,986 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.weight                                       loaded from backbone.body.layer3.6.bn1.weight                                       of shape (1024,)\n",
      "2022-04-02 12:03:53,986 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.bias                                         loaded from backbone.body.layer3.6.bn2.bias                                         of shape (1024,)\n",
      "2022-04-02 12:03:53,986 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.running_mean                                 loaded from backbone.body.layer3.6.bn2.running_mean                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,986 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.running_var                                  loaded from backbone.body.layer3.6.bn2.running_var                                  of shape (1024,)\n",
      "2022-04-02 12:03:53,986 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.weight                                       loaded from backbone.body.layer3.6.bn2.weight                                       of shape (1024,)\n",
      "2022-04-02 12:03:53,986 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.bias                                         loaded from backbone.body.layer3.6.bn3.bias                                         of shape (1024,)\n",
      "2022-04-02 12:03:53,986 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.running_mean                                 loaded from backbone.body.layer3.6.bn3.running_mean                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,986 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.running_var                                  loaded from backbone.body.layer3.6.bn3.running_var                                  of shape (1024,)\n",
      "2022-04-02 12:03:53,986 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.weight                                       loaded from backbone.body.layer3.6.bn3.weight                                       of shape (1024,)\n",
      "2022-04-02 12:03:53,986 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.conv1.weight                                     loaded from backbone.body.layer3.6.conv1.weight                                     of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,986 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.conv2.weight                                     loaded from backbone.body.layer3.6.conv2.weight                                     of shape (1024, 32, 3, 3)\n",
      "2022-04-02 12:03:53,986 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.conv3.weight                                     loaded from backbone.body.layer3.6.conv3.weight                                     of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,986 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.bias                                         loaded from backbone.body.layer3.7.bn1.bias                                         of shape (1024,)\n",
      "2022-04-02 12:03:53,986 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.running_mean                                 loaded from backbone.body.layer3.7.bn1.running_mean                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,986 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.running_var                                  loaded from backbone.body.layer3.7.bn1.running_var                                  of shape (1024,)\n",
      "2022-04-02 12:03:53,986 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.weight                                       loaded from backbone.body.layer3.7.bn1.weight                                       of shape (1024,)\n",
      "2022-04-02 12:03:53,986 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.bias                                         loaded from backbone.body.layer3.7.bn2.bias                                         of shape (1024,)\n",
      "2022-04-02 12:03:53,986 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.running_mean                                 loaded from backbone.body.layer3.7.bn2.running_mean                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,986 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.running_var                                  loaded from backbone.body.layer3.7.bn2.running_var                                  of shape (1024,)\n",
      "2022-04-02 12:03:53,986 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.weight                                       loaded from backbone.body.layer3.7.bn2.weight                                       of shape (1024,)\n",
      "2022-04-02 12:03:53,986 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.bias                                         loaded from backbone.body.layer3.7.bn3.bias                                         of shape (1024,)\n",
      "2022-04-02 12:03:53,986 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.running_mean                                 loaded from backbone.body.layer3.7.bn3.running_mean                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,987 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.running_var                                  loaded from backbone.body.layer3.7.bn3.running_var                                  of shape (1024,)\n",
      "2022-04-02 12:03:53,987 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.weight                                       loaded from backbone.body.layer3.7.bn3.weight                                       of shape (1024,)\n",
      "2022-04-02 12:03:53,987 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.conv1.weight                                     loaded from backbone.body.layer3.7.conv1.weight                                     of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,987 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.conv2.weight                                     loaded from backbone.body.layer3.7.conv2.weight                                     of shape (1024, 32, 3, 3)\n",
      "2022-04-02 12:03:53,987 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.conv3.weight                                     loaded from backbone.body.layer3.7.conv3.weight                                     of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,987 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.bias                                         loaded from backbone.body.layer3.8.bn1.bias                                         of shape (1024,)\n",
      "2022-04-02 12:03:53,987 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.running_mean                                 loaded from backbone.body.layer3.8.bn1.running_mean                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,987 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.running_var                                  loaded from backbone.body.layer3.8.bn1.running_var                                  of shape (1024,)\n",
      "2022-04-02 12:03:53,987 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.weight                                       loaded from backbone.body.layer3.8.bn1.weight                                       of shape (1024,)\n",
      "2022-04-02 12:03:53,987 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.bias                                         loaded from backbone.body.layer3.8.bn2.bias                                         of shape (1024,)\n",
      "2022-04-02 12:03:53,987 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.running_mean                                 loaded from backbone.body.layer3.8.bn2.running_mean                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,987 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.running_var                                  loaded from backbone.body.layer3.8.bn2.running_var                                  of shape (1024,)\n",
      "2022-04-02 12:03:53,987 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.weight                                       loaded from backbone.body.layer3.8.bn2.weight                                       of shape (1024,)\n",
      "2022-04-02 12:03:53,987 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.bias                                         loaded from backbone.body.layer3.8.bn3.bias                                         of shape (1024,)\n",
      "2022-04-02 12:03:53,987 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.running_mean                                 loaded from backbone.body.layer3.8.bn3.running_mean                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,987 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.running_var                                  loaded from backbone.body.layer3.8.bn3.running_var                                  of shape (1024,)\n",
      "2022-04-02 12:03:53,987 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.weight                                       loaded from backbone.body.layer3.8.bn3.weight                                       of shape (1024,)\n",
      "2022-04-02 12:03:53,987 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.conv1.weight                                     loaded from backbone.body.layer3.8.conv1.weight                                     of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,987 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.conv2.weight                                     loaded from backbone.body.layer3.8.conv2.weight                                     of shape (1024, 32, 3, 3)\n",
      "2022-04-02 12:03:53,987 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.conv3.weight                                     loaded from backbone.body.layer3.8.conv3.weight                                     of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,987 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.bias                                         loaded from backbone.body.layer3.9.bn1.bias                                         of shape (1024,)\n",
      "2022-04-02 12:03:53,987 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.running_mean                                 loaded from backbone.body.layer3.9.bn1.running_mean                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,987 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.running_var                                  loaded from backbone.body.layer3.9.bn1.running_var                                  of shape (1024,)\n",
      "2022-04-02 12:03:53,987 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.weight                                       loaded from backbone.body.layer3.9.bn1.weight                                       of shape (1024,)\n",
      "2022-04-02 12:03:53,987 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.bias                                         loaded from backbone.body.layer3.9.bn2.bias                                         of shape (1024,)\n",
      "2022-04-02 12:03:53,987 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.running_mean                                 loaded from backbone.body.layer3.9.bn2.running_mean                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,987 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.running_var                                  loaded from backbone.body.layer3.9.bn2.running_var                                  of shape (1024,)\n",
      "2022-04-02 12:03:53,987 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.weight                                       loaded from backbone.body.layer3.9.bn2.weight                                       of shape (1024,)\n",
      "2022-04-02 12:03:53,988 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.bias                                         loaded from backbone.body.layer3.9.bn3.bias                                         of shape (1024,)\n",
      "2022-04-02 12:03:53,988 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.running_mean                                 loaded from backbone.body.layer3.9.bn3.running_mean                                 of shape (1024,)\n",
      "2022-04-02 12:03:53,988 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.running_var                                  loaded from backbone.body.layer3.9.bn3.running_var                                  of shape (1024,)\n",
      "2022-04-02 12:03:53,988 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.weight                                       loaded from backbone.body.layer3.9.bn3.weight                                       of shape (1024,)\n",
      "2022-04-02 12:03:53,988 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.conv1.weight                                     loaded from backbone.body.layer3.9.conv1.weight                                     of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,988 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.conv2.weight                                     loaded from backbone.body.layer3.9.conv2.weight                                     of shape (1024, 32, 3, 3)\n",
      "2022-04-02 12:03:53,988 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.conv3.weight                                     loaded from backbone.body.layer3.9.conv3.weight                                     of shape (1024, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,988 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.bias                                             loaded from backbone.body.stem.bn1.bias                                             of shape (64,)\n",
      "2022-04-02 12:03:53,988 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.running_mean                                     loaded from backbone.body.stem.bn1.running_mean                                     of shape (64,)\n",
      "2022-04-02 12:03:53,988 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.running_var                                      loaded from backbone.body.stem.bn1.running_var                                      of shape (64,)\n",
      "2022-04-02 12:03:53,988 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.weight                                           loaded from backbone.body.stem.bn1.weight                                           of shape (64,)\n",
      "2022-04-02 12:03:53,988 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.conv1.weight                                         loaded from backbone.body.stem.conv1.weight                                         of shape (64, 3, 7, 7)\n",
      "2022-04-02 12:03:53,988 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.0.bn1.bias                  loaded from roi_heads.box.feature_extractor.head.layer4.0.bn1.bias                  of shape (2048,)\n",
      "2022-04-02 12:03:53,988 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.0.bn1.running_mean          loaded from roi_heads.box.feature_extractor.head.layer4.0.bn1.running_mean          of shape (2048,)\n",
      "2022-04-02 12:03:53,988 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.0.bn1.running_var           loaded from roi_heads.box.feature_extractor.head.layer4.0.bn1.running_var           of shape (2048,)\n",
      "2022-04-02 12:03:53,988 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.0.bn1.weight                loaded from roi_heads.box.feature_extractor.head.layer4.0.bn1.weight                of shape (2048,)\n",
      "2022-04-02 12:03:53,988 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.0.bn2.bias                  loaded from roi_heads.box.feature_extractor.head.layer4.0.bn2.bias                  of shape (2048,)\n",
      "2022-04-02 12:03:53,988 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.0.bn2.running_mean          loaded from roi_heads.box.feature_extractor.head.layer4.0.bn2.running_mean          of shape (2048,)\n",
      "2022-04-02 12:03:53,988 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.0.bn2.running_var           loaded from roi_heads.box.feature_extractor.head.layer4.0.bn2.running_var           of shape (2048,)\n",
      "2022-04-02 12:03:53,988 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.0.bn2.weight                loaded from roi_heads.box.feature_extractor.head.layer4.0.bn2.weight                of shape (2048,)\n",
      "2022-04-02 12:03:53,988 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.0.bn3.bias                  loaded from roi_heads.box.feature_extractor.head.layer4.0.bn3.bias                  of shape (2048,)\n",
      "2022-04-02 12:03:53,988 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.0.bn3.running_mean          loaded from roi_heads.box.feature_extractor.head.layer4.0.bn3.running_mean          of shape (2048,)\n",
      "2022-04-02 12:03:53,988 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.0.bn3.running_var           loaded from roi_heads.box.feature_extractor.head.layer4.0.bn3.running_var           of shape (2048,)\n",
      "2022-04-02 12:03:53,988 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.0.bn3.weight                loaded from roi_heads.box.feature_extractor.head.layer4.0.bn3.weight                of shape (2048,)\n",
      "2022-04-02 12:03:53,988 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.0.conv1.weight              loaded from roi_heads.box.feature_extractor.head.layer4.0.conv1.weight              of shape (2048, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,988 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.0.conv2.weight              loaded from roi_heads.box.feature_extractor.head.layer4.0.conv2.weight              of shape (2048, 64, 3, 3)\n",
      "2022-04-02 12:03:53,988 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.0.conv3.weight              loaded from roi_heads.box.feature_extractor.head.layer4.0.conv3.weight              of shape (2048, 2048, 1, 1)\n",
      "2022-04-02 12:03:53,988 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.0.downsample.0.weight       loaded from roi_heads.box.feature_extractor.head.layer4.0.downsample.0.weight       of shape (2048, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,989 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.0.downsample.1.bias         loaded from roi_heads.box.feature_extractor.head.layer4.0.downsample.1.bias         of shape (2048,)\n",
      "2022-04-02 12:03:53,989 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.0.downsample.1.running_mean loaded from roi_heads.box.feature_extractor.head.layer4.0.downsample.1.running_mean of shape (2048,)\n",
      "2022-04-02 12:03:53,989 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.0.downsample.1.running_var  loaded from roi_heads.box.feature_extractor.head.layer4.0.downsample.1.running_var  of shape (2048,)\n",
      "2022-04-02 12:03:53,989 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.0.downsample.1.weight       loaded from roi_heads.box.feature_extractor.head.layer4.0.downsample.1.weight       of shape (2048,)\n",
      "2022-04-02 12:03:53,989 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.1.bn1.bias                  loaded from roi_heads.box.feature_extractor.head.layer4.1.bn1.bias                  of shape (2048,)\n",
      "2022-04-02 12:03:53,989 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.1.bn1.running_mean          loaded from roi_heads.box.feature_extractor.head.layer4.1.bn1.running_mean          of shape (2048,)\n",
      "2022-04-02 12:03:53,989 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.1.bn1.running_var           loaded from roi_heads.box.feature_extractor.head.layer4.1.bn1.running_var           of shape (2048,)\n",
      "2022-04-02 12:03:53,989 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.1.bn1.weight                loaded from roi_heads.box.feature_extractor.head.layer4.1.bn1.weight                of shape (2048,)\n",
      "2022-04-02 12:03:53,989 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.1.bn2.bias                  loaded from roi_heads.box.feature_extractor.head.layer4.1.bn2.bias                  of shape (2048,)\n",
      "2022-04-02 12:03:53,989 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.1.bn2.running_mean          loaded from roi_heads.box.feature_extractor.head.layer4.1.bn2.running_mean          of shape (2048,)\n",
      "2022-04-02 12:03:53,989 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.1.bn2.running_var           loaded from roi_heads.box.feature_extractor.head.layer4.1.bn2.running_var           of shape (2048,)\n",
      "2022-04-02 12:03:53,989 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.1.bn2.weight                loaded from roi_heads.box.feature_extractor.head.layer4.1.bn2.weight                of shape (2048,)\n",
      "2022-04-02 12:03:53,989 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.1.bn3.bias                  loaded from roi_heads.box.feature_extractor.head.layer4.1.bn3.bias                  of shape (2048,)\n",
      "2022-04-02 12:03:53,989 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.1.bn3.running_mean          loaded from roi_heads.box.feature_extractor.head.layer4.1.bn3.running_mean          of shape (2048,)\n",
      "2022-04-02 12:03:53,989 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.1.bn3.running_var           loaded from roi_heads.box.feature_extractor.head.layer4.1.bn3.running_var           of shape (2048,)\n",
      "2022-04-02 12:03:53,989 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.1.bn3.weight                loaded from roi_heads.box.feature_extractor.head.layer4.1.bn3.weight                of shape (2048,)\n",
      "2022-04-02 12:03:53,989 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.1.conv1.weight              loaded from roi_heads.box.feature_extractor.head.layer4.1.conv1.weight              of shape (2048, 2048, 1, 1)\n",
      "2022-04-02 12:03:53,989 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.1.conv2.weight              loaded from roi_heads.box.feature_extractor.head.layer4.1.conv2.weight              of shape (2048, 64, 3, 3)\n",
      "2022-04-02 12:03:53,989 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.1.conv3.weight              loaded from roi_heads.box.feature_extractor.head.layer4.1.conv3.weight              of shape (2048, 2048, 1, 1)\n",
      "2022-04-02 12:03:53,989 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.2.bn1.bias                  loaded from roi_heads.box.feature_extractor.head.layer4.2.bn1.bias                  of shape (2048,)\n",
      "2022-04-02 12:03:53,989 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.2.bn1.running_mean          loaded from roi_heads.box.feature_extractor.head.layer4.2.bn1.running_mean          of shape (2048,)\n",
      "2022-04-02 12:03:53,989 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.2.bn1.running_var           loaded from roi_heads.box.feature_extractor.head.layer4.2.bn1.running_var           of shape (2048,)\n",
      "2022-04-02 12:03:53,989 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.2.bn1.weight                loaded from roi_heads.box.feature_extractor.head.layer4.2.bn1.weight                of shape (2048,)\n",
      "2022-04-02 12:03:53,989 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.2.bn2.bias                  loaded from roi_heads.box.feature_extractor.head.layer4.2.bn2.bias                  of shape (2048,)\n",
      "2022-04-02 12:03:53,989 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.2.bn2.running_mean          loaded from roi_heads.box.feature_extractor.head.layer4.2.bn2.running_mean          of shape (2048,)\n",
      "2022-04-02 12:03:53,989 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.2.bn2.running_var           loaded from roi_heads.box.feature_extractor.head.layer4.2.bn2.running_var           of shape (2048,)\n",
      "2022-04-02 12:03:53,989 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.2.bn2.weight                loaded from roi_heads.box.feature_extractor.head.layer4.2.bn2.weight                of shape (2048,)\n",
      "2022-04-02 12:03:53,989 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.2.bn3.bias                  loaded from roi_heads.box.feature_extractor.head.layer4.2.bn3.bias                  of shape (2048,)\n",
      "2022-04-02 12:03:53,990 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.2.bn3.running_mean          loaded from roi_heads.box.feature_extractor.head.layer4.2.bn3.running_mean          of shape (2048,)\n",
      "2022-04-02 12:03:53,990 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.2.bn3.running_var           loaded from roi_heads.box.feature_extractor.head.layer4.2.bn3.running_var           of shape (2048,)\n",
      "2022-04-02 12:03:53,990 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.2.bn3.weight                loaded from roi_heads.box.feature_extractor.head.layer4.2.bn3.weight                of shape (2048,)\n",
      "2022-04-02 12:03:53,990 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.2.conv1.weight              loaded from roi_heads.box.feature_extractor.head.layer4.2.conv1.weight              of shape (2048, 2048, 1, 1)\n",
      "2022-04-02 12:03:53,990 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.2.conv2.weight              loaded from roi_heads.box.feature_extractor.head.layer4.2.conv2.weight              of shape (2048, 64, 3, 3)\n",
      "2022-04-02 12:03:53,990 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.head.layer4.2.conv3.weight              loaded from roi_heads.box.feature_extractor.head.layer4.2.conv3.weight              of shape (2048, 2048, 1, 1)\n",
      "2022-04-02 12:03:53,990 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.bbox_pred.bias                                  loaded from roi_heads.box.predictor.bbox_pred.bias                                  of shape (6380,)\n",
      "2022-04-02 12:03:53,990 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.bbox_pred.weight                                loaded from roi_heads.box.predictor.bbox_pred.weight                                of shape (6380, 2048)\n",
      "2022-04-02 12:03:53,990 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.cls_score.bias                                  loaded from roi_heads.box.predictor.cls_score.bias                                  of shape (1595,)\n",
      "2022-04-02 12:03:53,990 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.cls_score.weight                                loaded from roi_heads.box.predictor.cls_score.weight                                of shape (1595, 2048)\n",
      "2022-04-02 12:03:53,990 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.0                                     loaded from rpn.anchor_generator.cell_anchors.0                                     of shape (15, 4)\n",
      "2022-04-02 12:03:53,990 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.bias                                                 loaded from rpn.head.bbox_pred.bias                                                 of shape (60,)\n",
      "2022-04-02 12:03:53,990 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.weight                                               loaded from rpn.head.bbox_pred.weight                                               of shape (60, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,990 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.bias                                                loaded from rpn.head.cls_logits.bias                                                of shape (15,)\n",
      "2022-04-02 12:03:53,990 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.weight                                              loaded from rpn.head.cls_logits.weight                                              of shape (15, 1024, 1, 1)\n",
      "2022-04-02 12:03:53,990 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.conv.bias                                                      loaded from rpn.head.conv.bias                                                      of shape (1024,)\n",
      "2022-04-02 12:03:53,990 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.conv.weight                                                    loaded from rpn.head.conv.weight                                                    of shape (1024, 1024, 3, 3)\n",
      "{'hw': 'CIFAR-100.test.hw.tsv', 'img': 'CIFAR-100.test.tsv', 'label': 'CIFAR-100.test.label.tsv', 'linelist': 'CIFAR-100.test.linelist.tsv'}\n",
      "{'hw': 'CIFAR-100.test.hw.tsv', 'img': 'CIFAR-100.test.tsv', 'label': 'CIFAR-100.test.label.tsv', 'linelist': 'CIFAR-100.test.linelist.tsv'}\n",
      "2022-04-02 12:03:55,108 maskrcnn_benchmark.inference INFO: Start evaluation on CIFAR-100.test.yaml dataset(50000 images).\n",
      "INFO:maskrcnn_benchmark.inference:Start evaluation on CIFAR-100.test.yaml dataset(50000 images).\n",
      "  0%|                                                 | 0/25000 [00:00<?, ?it/s]INFO:maskrcnn_benchmark.inference:Start evaluation on CIFAR-100.test.yaml dataset(50000 images).\n",
      "100%|███████████████████████████████████| 25000/25000 [5:13:31<00:00,  1.33it/s]\n",
      "100%|███████████████████████████████████| 25000/25000 [5:35:06<00:00,  1.24it/s]\n",
      "2022-04-02 17:39:01,642 maskrcnn_benchmark.inference INFO: Total run time: 5:35:06.533199 (0.8042613279438019 s / img per device, on 2 devices)\n",
      "INFO:maskrcnn_benchmark.inference:Total run time: 5:35:06.533199 (0.8042613279438019 s / img per device, on 2 devices)\n",
      "2022-04-02 17:39:01,642 maskrcnn_benchmark.inference INFO: Model inference time: 5:29:47.433313 (0.79149733253479 s / img per device, on 2 devices)\n",
      "INFO:maskrcnn_benchmark.inference:Model inference time: 5:29:47.433313 (0.79149733253479 s / img per device, on 2 devices)\n",
      "INFO:maskrcnn_benchmark.inference:Total run time: 5:35:06.060805 (0.8042424321842193 s / img per device, on 2 devices)\n",
      "INFO:maskrcnn_benchmark.inference:Model inference time: 5:08:12.245438 (0.7396898175144195 s / img per device, on 2 devices)\n",
      "2022-04-02 17:42:20,908 maskrcnn_benchmark.inference INFO: Convert prediction results to tsv format and save.\n",
      "INFO:maskrcnn_benchmark.inference:Convert prediction results to tsv format and save.\n",
      "2022-04-02 17:43:13,262 maskrcnn_benchmark.inference INFO: Skip performance evaluation and return.\n",
      "INFO:maskrcnn_benchmark.inference:Skip performance evaluation and return.\n"
     ]
    }
   ],
   "source": [
    "! cd {sg_benchmark_path} && rm -rf output/{DATASET}\n",
    "! cd {sg_benchmark_path} && conda activate oscar && CUDA_VISIBLE_DEVICES=6,7 python -m torch.distributed.launch --nproc_per_node=2 tools/test_sg_net.py \\\n",
    "  --config-file sgg_configs/vgattr/vinvl_x152c4.yaml \\\n",
    "  TEST.IMS_PER_BATCH 2 \\\n",
    "  DATASETS.TEST \"('{DATASET}.test.yaml', )\"\\\n",
    "  MODEL.WEIGHT pretrained_model/vinvl_vg_x152c4.pth \\\n",
    "  MODEL.ROI_HEADS.NMS_FILTER 1 \\\n",
    "  MODEL.ROI_HEADS.SCORE_THRESH 0.2 \\\n",
    "  TEST.OUTPUT_FEATURE True \\\n",
    "  OUTPUT_DIR output/{DATASET} \\\n",
    "  DATA_DIR tools/mini_tsv/data \\\n",
    "  TEST.IGNORE_BOX_REGRESSION True \\\n",
    "  MODEL.ATTRIBUTE_ON True \\\n",
    "  DATASETS.LABELMAP_FILE visualgenome/VG-SGG-dicts-vgoi6-clipped.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d26a23ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             1\n",
      "0                                             \n",
      "cattle_0         [{'height': 32, 'width': 32}]\n",
      "dinosaur_1       [{'height': 32, 'width': 32}]\n",
      "apple_2          [{'height': 32, 'width': 32}]\n",
      "boy_3            [{'height': 32, 'width': 32}]\n",
      "aquarium_fish_4  [{'height': 32, 'width': 32}]\n",
      "                 0                                                  1\n",
      "0         cattle_0  [{'rect': [15.091263771057129, 18.420007705688...\n",
      "1       dinosaur_1  [{'rect': [8.743090629577637, 21.0789527893066...\n",
      "2          apple_2  [{'rect': [0.0, 0.0, 19.87682342529297, 26.465...\n",
      "3            boy_3  [{'rect': [9.654656410217285, 6.23761081695556...\n",
      "4  aquarium_fish_4  [{'rect': [0.0, 9.214780807495117, 21.26975631...\n",
      "                 0                                                  1  \\\n",
      "0         cattle_0  [{'rect': [15.091263771057129, 18.420007705688...   \n",
      "1       dinosaur_1  [{'rect': [8.743090629577637, 21.0789527893066...   \n",
      "2          apple_2  [{'rect': [0.0, 0.0, 19.87682342529297, 26.465...   \n",
      "3            boy_3  [{'rect': [9.654656410217285, 6.23761081695556...   \n",
      "4  aquarium_fish_4  [{'rect': [0.0, 9.214780807495117, 21.26975631...   \n",
      "\n",
      "                                             feature  \\\n",
      "0  {\"features\": \"AAAAAAAAAAAAAAAArE0NQAumwj8AAAAA...   \n",
      "1  {\"features\": \"AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA...   \n",
      "2  {\"features\": \"Lk4GQHNsGT4AAAAAosOPPxXTVT05vIY+...   \n",
      "3  {\"features\": \"AAAAAAAAAAAAAAAAALkjQMWiGD8u/B1A...   \n",
      "4  {\"features\": \"8+oKPQAAAAAAAAAAXaAfQEgfBj8AAAAA...   \n",
      "\n",
      "                                               label  \n",
      "0  [{\"class\": \"Face\", \"conf\": 0.5999839305877686,...  \n",
      "1  [{\"class\": \"Leg\", \"conf\": 0.7989650368690491, ...  \n",
      "2  [{\"class\": \"Background\", \"conf\": 0.43069040775...  \n",
      "3  [{\"class\": \"Face\", \"conf\": 0.9889256358146667,...  \n",
      "4  [{\"class\": \"Person\", \"conf\": 0.470397591590881...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import ast\n",
    "import numpy as np\n",
    "import base64\n",
    "\n",
    "data_dir = os.path.join(sg_benchmark_path, 'tools/mini_tsv/data')\n",
    "sg_tsv = os.path.join(sg_benchmark_path, 'output/{}/inference/vinvl_vg_x152c4/predictions.tsv'.format(DATASET))\n",
    "\n",
    "# Height and width data\n",
    "hw_df = pd.read_csv(os.path.join(data_dir, '{}.test.hw.tsv'.format(DATASET)), sep='\\t', header=None, converters={1:ast.literal_eval}, index_col=0)\n",
    "print(hw_df.head())\n",
    "\n",
    "# bboxes, class, confidence and spacial features\n",
    "df = pd.read_csv(sg_tsv, sep='\\t', header=None, converters={1:json.loads})\n",
    "df[1] = df[1].apply(lambda x:x['objects'])\n",
    "print(df.head())\n",
    "\n",
    "def generate_additional_features(rect, h, w):\n",
    "    mask = np.array([w, h, w, h], dtype=np.float32)\n",
    "    rect = np.clip(rect / mask, 0, 1)\n",
    "    res = np.hstack((rect, (rect[3] - rect[1], rect[2] - rect[0])))\n",
    "    return res.astype(np.float32)\n",
    "\n",
    "def generate_features(x):\n",
    "    idx, data, num_boxes = x[0], x[1], len(x[1] )\n",
    "    h, w, features_arr = hw_df.loc[idx, 1][0]['height'], hw_df.loc[idx,1][0]['width'], []\n",
    "\n",
    "    for i in range(num_boxes):\n",
    "        features = np.frombuffer(base64.b64decode(data[i]['feature']),np.float32)\n",
    "        pos_feat = generate_additional_features(data[i]['rect'],h,w)\n",
    "        x = np.hstack((features,pos_feat))\n",
    "        features_arr.append(x.astype(np.float32))\n",
    "\n",
    "    features = np.vstack(tuple(features_arr))\n",
    "    features = base64.b64encode(features).decode(\"utf-8\")\n",
    "    return {\"features\":features, \"num_boxes\":num_boxes}\n",
    "\n",
    "def generate_labels(x):\n",
    "    data = x[1]\n",
    "    res = [{\"class\":el['class'].capitalize(),\"conf\":el['conf'], \"rect\": el['rect']} for el in data]\n",
    "    return res\n",
    "\n",
    "df['feature'] = df.apply(generate_features,axis=1)\n",
    "df['feature'] = df['feature'].apply(json.dumps)\n",
    "\n",
    "df['label'] = df.apply(generate_labels,axis=1)\n",
    "df['label'] = df['label'].apply(json.dumps)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "output_dir = os.path.join(oscar_path, 'oscar/my_data')\n",
    "label_file = os.path.join(output_dir, '{}.label.tsv'.format(DATASET))\n",
    "feature_file = os.path.join(output_dir, '{}.features.tsv'.format(DATASET))\n",
    "\n",
    "from maskrcnn_benchmark.structures.tsv_file_ops import tsv_reader, tsv_writer\n",
    "tsv_writer(df[[0,'label']].values.tolist(), label_file)\n",
    "tsv_writer(df[[0,'feature']].values.tolist(), feature_file)\n",
    "\n",
    "import yaml\n",
    "import os.path as op\n",
    "yaml_dict = {\"label\": '{}.label.tsv'.format(DATASET),\n",
    "             \"feature\": '{}.features.tsv'.format(DATASET)}\n",
    "\n",
    "with open(op.join(output_dir, '{}.test.yaml'.format(DATASET)), 'w') as file:\n",
    "        yaml.dump(yaml_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef184e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "Init distributed training on local rank 0\n",
      "Init distributed training on local rank 1\n",
      "Init distributed training on local rank 7\n",
      "Init distributed training on local rank 6\n",
      "Init distributed training on local rank 3\n",
      "Init distributed training on local rank 4\n",
      "Init distributed training on local rank 2\n",
      "Init distributed training on local rank 5\n",
      "Device: cuda, n_gpu: 8\n",
      "Device: cuda, n_gpu: 8\n",
      "Device: cuda, n_gpu: 8\n",
      "2022-03-15 14:17:13,088 vlpretrain WARNING: Device: cuda, n_gpu: 8\n",
      "Device: cuda, n_gpu: 8\n",
      "Device: cuda, n_gpu: 8\n",
      "Device: cuda, n_gpu: 8\n",
      "Device: cuda, n_gpu: 8\n",
      "2022-03-15 14:17:13,158 vlpretrain WARNING: Override max_seq_length to 50 = max_gen_length:20 + od_labels_len:30\n",
      "Override max_seq_length to 50 = max_gen_length:20 + od_labels_len:30\n",
      "Override max_seq_length to 50 = max_gen_length:20 + od_labels_len:30\n",
      "Override max_seq_length to 50 = max_gen_length:20 + od_labels_len:30\n",
      "Override max_seq_length to 50 = max_gen_length:20 + od_labels_len:30\n",
      "Override max_seq_length to 50 = max_gen_length:20 + od_labels_len:30\n",
      "Override max_seq_length to 50 = max_gen_length:20 + od_labels_len:30\n",
      "Override max_seq_length to 50 = max_gen_length:20 + od_labels_len:30\n",
      "2022-03-15 14:17:13,191 vlpretrain INFO: Evaluate the following checkpoint: pretrained_models/image_captioning/coco_captioning_large_scst/checkpoint-4-50000/\n",
      "2022-03-15 14:17:30,237 vlpretrain INFO: Training/evaluation parameters Namespace(adam_epsilon=1e-08, add_od_labels=True, cider_cached_tokens='coco-train-words.p', config_name='', data_dir='datasets/coco_caption', device=device(type='cuda'), distributed=True, do_eval=False, do_lower_case=True, do_test=True, do_train=False, drop_out=0.1, drop_worst_after=0, drop_worst_ratio=0, eval_model_dir='pretrained_models/image_captioning/coco_captioning_large_scst/checkpoint-4-50000/', evaluate_during_training=False, freeze_embedding=False, gradient_accumulation_steps=1, img_feature_dim=2054, img_feature_type='frcnn', label_smoothing=0, learning_rate=3e-05, length_penalty=1, local_rank=0, logging_steps=20, loss_type='sfmx', mask_prob=0.15, max_gen_length=20, max_grad_norm=1.0, max_img_seq_length=50, max_masked_tokens=3, max_seq_a_length=40, max_seq_length=50, max_steps=-1, min_constraints_to_satisfy=2, model_name_or_path=None, no_cuda=False, num_beams=1, num_gpus=8, num_keep_best=1, num_labels=2, num_return_sequences=1, num_train_epochs=40, num_workers=0, output_dir='output/', output_hidden_states=False, output_mode='classification', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, repetition_penalty=1, save_steps=-1, sc_baseline_type='greedy', sc_beam_size=1, sc_train_sample_n=5, scheduler='linear', scst=False, seed=88, temperature=1, test_yaml='oscar/my_data/CIFAR-100.test.yaml', tie_weights=False, tokenizer_name='', top_k=0, top_p=1, train_yaml='train.yaml', use_cbs=False, val_yaml='val.yaml', warmup_steps=0, weight_decay=0.05)\n",
      "2022-03-15 14:17:30,237 vlpretrain INFO: Evaluate on dataset: oscar/my_data/CIFAR-100.test.yaml\n",
      "98it [11:02,  6.76s/it]\n",
      "INFO:vlpretrain:Inference model computing time: 6.6244743259585634 seconds per batch\n",
      "98it [11:06,  6.80s/it]\n",
      "INFO:vlpretrain:Inference model computing time: 6.678200120828589 seconds per batch\n",
      "98it [11:06,  6.80s/it]\n",
      "INFO:vlpretrain:Inference model computing time: 6.679810431538796 seconds per batch\n",
      "98it [11:08,  6.82s/it]\n",
      "2022-03-15 14:28:39,846 vlpretrain INFO: Inference model computing time: 6.693864666685766 seconds per batch\n",
      "INFO:vlpretrain:Inference model computing time: 6.693864666685766 seconds per batch\n",
      "98it [11:21,  6.96s/it]\n",
      "INFO:vlpretrain:Inference model computing time: 6.838367051007796 seconds per batch\n",
      "98it [11:24,  6.98s/it]\n",
      "INFO:vlpretrain:Inference model computing time: 6.850076373742551 seconds per batch\n",
      "98it [11:32,  7.07s/it]\n",
      "INFO:vlpretrain:Inference model computing time: 6.9362411985591965 seconds per batch\n",
      "98it [11:38,  7.12s/it]\n",
      "INFO:vlpretrain:Inference model computing time: 6.998139198945493 seconds per batch\n",
      "INFO:vlpretrain:Prediction results saved to: pretrained_models/image_captioning/coco_captioning_large_scst/checkpoint-4-50000/pred.coco_caption.CIFAR-100.test.beam1.max20.odlabels.tsv\n",
      "INFO:vlpretrain:Prediction results saved to: pretrained_models/image_captioning/coco_captioning_large_scst/checkpoint-4-50000/pred.coco_caption.CIFAR-100.test.beam1.max20.odlabels.tsv\n",
      "INFO:vlpretrain:Prediction results saved to: pretrained_models/image_captioning/coco_captioning_large_scst/checkpoint-4-50000/pred.coco_caption.CIFAR-100.test.beam1.max20.odlabels.tsv\n",
      "2022-03-15 14:29:12,060 vlpretrain INFO: Prediction results saved to: pretrained_models/image_captioning/coco_captioning_large_scst/checkpoint-4-50000/pred.coco_caption.CIFAR-100.test.beam1.max20.odlabels.tsv\n",
      "INFO:vlpretrain:Prediction results saved to: pretrained_models/image_captioning/coco_captioning_large_scst/checkpoint-4-50000/pred.coco_caption.CIFAR-100.test.beam1.max20.odlabels.tsv\n",
      "INFO:vlpretrain:Prediction results saved to: pretrained_models/image_captioning/coco_captioning_large_scst/checkpoint-4-50000/pred.coco_caption.CIFAR-100.test.beam1.max20.odlabels.tsv\n",
      "INFO:vlpretrain:Prediction results saved to: pretrained_models/image_captioning/coco_captioning_large_scst/checkpoint-4-50000/pred.coco_caption.CIFAR-100.test.beam1.max20.odlabels.tsv\n",
      "INFO:vlpretrain:Prediction results saved to: pretrained_models/image_captioning/coco_captioning_large_scst/checkpoint-4-50000/pred.coco_caption.CIFAR-100.test.beam1.max20.odlabels.tsv\n",
      "INFO:vlpretrain:Prediction results saved to: pretrained_models/image_captioning/coco_captioning_large_scst/checkpoint-4-50000/pred.coco_caption.CIFAR-100.test.beam1.max20.odlabels.tsv\n"
     ]
    }
   ],
   "source": [
    "! cd {oscar_path} && conda activate oscar && CUDA_VISIBLE_DEVICES=5,6,7 python -m torch.distributed.launch --nproc_per_node=3 oscar/run_captioning.py \\\n",
    "    --eval_model_dir pretrained_models/image_captioning/coco_captioning_large_scst/checkpoint-4-50000/\\\n",
    "    --do_test \\\n",
    "    --test_yaml oscar/my_data/{DATASET}.test.yaml \\\n",
    "    --do_lower_case \\\n",
    "    --add_od_labels \\\n",
    "    --output_dir output/ \\\n",
    "    --num_workers 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97eeaf86",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      img                                           raw_data  \\\n",
      "0       1  [{\"caption\": \"a green statue of a man standing...   \n",
      "1       2  [{\"caption\": \"a blurry picture of a purple obj...   \n",
      "2       3  [{\"caption\": \"a blurry picture of a person wit...   \n",
      "3  fish_4  [{\"caption\": \"a blurry image of a building in ...   \n",
      "4       5  [{\"caption\": \"a blurry picture of a blue and w...   \n",
      "\n",
      "                                             caption      conf      class  \n",
      "0  a green statue of a man standing in front of a...  0.812326   dinosaur  \n",
      "1    a blurry picture of a purple object in the air.  0.868000      apple  \n",
      "2    a blurry picture of a person with a blue shirt.  0.934274        boy  \n",
      "3    a blurry image of a building in the background.  0.893749   aquarium  \n",
      "4       a blurry picture of a blue and white object.  0.957596  telephone  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "coco_inf_path = os.path.join(oscar_path, 'pretrained_models/image_captioning/coco_captioning_large_scst/checkpoint-4-50000/pred.coco_caption.{}.test.beam1.max20.odlabels.tsv'.format(DATASET))\n",
    "\n",
    "df = pd.read_csv(coco_inf_path, sep='\\t')\n",
    "df.columns = ['img', 'raw_data']\n",
    "objects = df.iloc[:,1].apply(json.loads)\n",
    "df['caption'] = objects.apply(lambda x: x[0]['caption'])\n",
    "df['conf'] = objects.apply(lambda x: x[0]['conf'])\n",
    "df['class'] = df['img'].apply(lambda x: x.split('_')[0])\n",
    "df['img'] = df['img'].apply(lambda x: '_'.join(x.split('_')[1:]))\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f7290438",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/nobackup-slow/dataset/cifarpy/frog/15816.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/tmp/ipykernel_3989707/3384748871.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/oscar/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2952\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2953\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2954\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/nobackup-slow/dataset/cifarpy/frog/15816.jpg'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/tmp/ipykernel_3989707/3384748871.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/oscar/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2952\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2953\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2954\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/nobackup-slow/dataset/cifarpy/frog/15816.jpg'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(dpi = 100, figsize=[20,20])\n",
    "\n",
    "N = 6\n",
    "for c, i in enumerate(np.random.randint(0, len(df), size=N)):\n",
    "    test_image = str(df.iloc[i]['img'])+'.jpg'\n",
    "    test_class = str(df.iloc[i]['class'])\n",
    "    if DATASET in ['iNaturalist', 'Places', 'SUN']: test_class = 'images'\n",
    "    test_caption = df.iloc[i]['caption']\n",
    "\n",
    "    try:\n",
    "        img = Image.open(os.path.join(data_path, test_class, test_image))\n",
    "    except:\n",
    "        img = Image.open(os.path.join(data_path, test_class, test_image))\n",
    "    \n",
    "    ax = fig.add_subplot(int(N/2), 2, c + 1)\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    txt = ax.text(0, -10, test_caption, wrap=True, fontsize='xx-large')\n",
    "    txt._get_wrap_line_width = lambda : 800\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x2000 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(dpi = 100, figsize=[20,20])\n",
    "\n",
    "N = 6\n",
    "for c, i in enumerate(np.random.randint(0, len(df), size=N)):\n",
    "    img, _ = img_ds[i]\n",
    "    test_caption = df.iloc[i]['caption']\n",
    "    \n",
    "    ax = fig.add_subplot(int(N/2), 2, c + 1)\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    txt = ax.text(0, -10, test_caption, wrap=True, fontsize='xx-large')\n",
    "    txt._get_wrap_line_width = lambda : 800\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bb244753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "captions.ipynb\t       gen_captions\t\t    play_with_clip.py  utils\n",
      "CIFAR-10_captions.tsv  img_templates\t\t    random_test.py\n",
      "data\t\t       Interacting_with_CLIP.ipynb  README.md\n",
      "eval_ood_detection.py  models\t\t\t    train_clip.py\n"
     ]
    }
   ],
   "source": [
    "df[['img', 'caption', 'class']].to_csv('{}_captions.tsv'.format(DATASET), header=None, index=False, sep='\\t')\n",
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cf99a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.read_csv('imagenet_captions.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a621c84b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a7f2ca3f72c09034bcf7afe4899551dba2f012c2fbde530c711aacb8021617e0"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('oscar': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
